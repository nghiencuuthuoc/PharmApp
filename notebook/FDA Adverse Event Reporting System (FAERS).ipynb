{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ece5d2-78f7-43e1-8d5b-3195770074b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#pandas\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdd\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#function\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_pd_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _folder_to_filestems, _lowercase, _tonumeric, _todatetime, \\\n\u001b[0;32m     20\u001b[0m     _groupby, _firstvalue_join_notna\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dask'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#import\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import shutil\n",
    "import requests\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#pandas\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "#function\n",
    "from _pd_utils import _folder_to_filestems, _lowercase, _tonumeric, _todatetime, \\\n",
    "    _groupby, _firstvalue_join_notna\n",
    "\n",
    "\n",
    "#variable\n",
    "from _census import statefips_dict, statenames_dict, statenames_list\n",
    "\n",
    "\n",
    "#_beacagdp1 \n",
    "#https://apps.bea.gov/regional/downloadzip.cfm, Gross domestic product (GDP): \"CAGDP1\"\n",
    "#https://www.bea.gov/help/glossary\n",
    "folders=[\"ciani/data/beacagdp1\", \"ciani/_beacagdp1\"]\n",
    "items=[\"CAGDP1__ALL_AREAS_2017_2022\", \"beacagdp1\"]\n",
    "def _beacagdp1(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"GeoFIPS\",\n",
    "        \"LineCode\",\n",
    "        \"2017\",\n",
    "        \"2018\",\n",
    "        \"2019\",\n",
    "        \"2020\",\n",
    "        \"2021\",\n",
    "        \"2022\",\n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.csv\"\n",
    "    sep=\",\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        engine=\"python\",\n",
    "        dtype=\"string\",\n",
    "        skipinitialspace=True,\n",
    "        skipfooter=4,\n",
    "        na_values=[\"(NA)\"],\n",
    "        #nrows=100,\n",
    "        encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        ) \n",
    "        \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"GeoFIPS\",\n",
    "        \"LineCode\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"LineCode\"]==\"3\"]\n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "    #statefips\n",
    "    df[\"statefips\"]=df[\"GeoFIPS\"].str[0:2]\n",
    "\n",
    "    #countyfips\n",
    "    df[\"countyfips\"]=df[\"GeoFIPS\"].str[2:5]\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"countyfips\"]!=\"000\"]\n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "    #melt\n",
    "    id_vars=[\n",
    "        \"GeoFIPS\",\n",
    "        ]\n",
    "    value_vars=[\n",
    "        \"2017\",\n",
    "        \"2018\",\n",
    "        \"2019\",\n",
    "        \"2020\",\n",
    "        \"2021\",\n",
    "        \"2022\",\n",
    "        ]\n",
    "    var_name=\"year\"\n",
    "    value_name=\"gdp\"\n",
    "    df=pd.melt(\n",
    "        frame=df,\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name=var_name,\n",
    "        value_name=value_name,\n",
    "        )\n",
    "\n",
    "    #sortvalues \n",
    "    sortvalues_cols=[\n",
    "        \"GeoFIPS\",\n",
    "        \"year\",\n",
    "        ]        \n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "    \n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"GeoFIPS\",\n",
    "        \"gdp\",\n",
    "        \"year\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_beacagdp1(folders, items)\n",
    "\n",
    "\n",
    "#_beacainc1 \n",
    "#https://apps.bea.gov/regional/downloadzip.cfm, Personal income (state and local): \"CAINC1\"\n",
    "#https://www.bea.gov/help/glossary\n",
    "folders=[\"ciani/data/beacainc1\", \"ciani/_beacainc1\"]\n",
    "items=[\"CAINC1__ALL_AREAS_1969_2022\", \"beacainc1\"]\n",
    "def _beacainc1(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"GeoFIPS\",\n",
    "        \"LineCode\",\n",
    "        \"2017\",\n",
    "        \"2018\",\n",
    "        \"2019\",\n",
    "        \"2020\",\n",
    "        \"2021\",\n",
    "        \"2022\",\n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.csv\"\n",
    "    sep=\",\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        engine=\"python\",\n",
    "        dtype=\"string\",\n",
    "        skipinitialspace=True,\n",
    "        skipfooter=4,\n",
    "        na_values=[\"(NA)\"],\n",
    "        #nrows=100,\n",
    "        encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        ) \n",
    "        \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"GeoFIPS\",\n",
    "        \"LineCode\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"LineCode\"]==\"3\"]\n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "    #statefips\n",
    "    df[\"statefips\"]=df[\"GeoFIPS\"].str[0:2]\n",
    "\n",
    "    #countyfips\n",
    "    df[\"countyfips\"]=df[\"GeoFIPS\"].str[2:5]\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"countyfips\"]!=\"000\"]\n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "    #melt\n",
    "    id_vars=[\n",
    "        \"GeoFIPS\",\n",
    "        ]\n",
    "    value_vars=[\n",
    "        \"2017\",\n",
    "        \"2018\",\n",
    "        \"2019\",\n",
    "        \"2020\",\n",
    "        \"2021\",\n",
    "        \"2022\",\n",
    "        ]\n",
    "    var_name=\"year\"\n",
    "    value_name=\"inc\"\n",
    "    df=pd.melt(\n",
    "        frame=df,\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name=var_name,\n",
    "        value_name=value_name,\n",
    "        )\n",
    "\n",
    "    #sortvalues \n",
    "    sortvalues_cols=[\n",
    "        \"GeoFIPS\",\n",
    "        \"year\",\n",
    "        ]        \n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "    \n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"GeoFIPS\",\n",
    "        \"inc\",\n",
    "        \"year\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_beacainc1(folders, items)\n",
    "\n",
    "\n",
    "#_faers_extract\n",
    "#https://fis.fda.gov/extensions/FPD-QDE-FAERS/FPD-QDE-FAERS.html\n",
    "folders=[\"ciani/data/faers\", \"ciani/_faers\"]\n",
    "items=[]\n",
    "def _faers_extract(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    #result=items[0]\n",
    "\n",
    "    #zipresults\n",
    "    zipresults=f\"{results}/zip\"\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems = _folder_to_filestems(resources)\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(files)\n",
    "\n",
    "    #tot\n",
    "    tot=nobs-1\n",
    "\n",
    "    #for\n",
    "    for i, file in enumerate(files):\n",
    "\n",
    "        #ZipFile\n",
    "        filepath=f\"{file}\"\n",
    "        with ZipFile(filepath, \"r\") as myzip:\n",
    "\n",
    "            #namelist\n",
    "            namelist=myzip.namelist()\n",
    "\n",
    "            #namelist\n",
    "            namelist=[x for x in namelist if x.endswith(\".txt\") or x.endswith(\".TXT\")]\n",
    "\n",
    "            #for\n",
    "            for j, tempfile in enumerate(namelist):\n",
    "\n",
    "                #stem\n",
    "                tempfilestem=Path(tempfile).stem\n",
    "\n",
    "                #lower\n",
    "                tempfilestem=tempfilestem.lower()\n",
    "\n",
    "                #extract\n",
    "                member=f\"{tempfile}\"\n",
    "                path=f\"{zipresults}\"\n",
    "                myzip.extract(member, path)\n",
    "\n",
    "                #rename\n",
    "                p=Path(f\"{zipresults}/{tempfile}\")\n",
    "                target=f\"{rawresults}/{tempfilestem}.txt\"\n",
    "                p.rename(target)\n",
    "\n",
    "        #print\n",
    "        print(f\"{i}/{tot} - {file} - done\")\n",
    "\n",
    "    #'''\n",
    "#_faers_extract(folders, items)\n",
    "\n",
    "\n",
    "#_faers_demo\n",
    "#https://fis.fda.gov/extensions/FPD-QDE-FAERS/FPD-QDE-FAERS.html\n",
    "folders=[\"ciani/data/faers\", \"ciani/_faers\"]\n",
    "items=[\"demo\"]\n",
    "def _faers_demo(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    result=items[0]\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"\n",
    "\n",
    "    #cleanresults\n",
    "    cleanresults=f\"{results}/clean\"\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems = _folder_to_filestems(rawresults)\n",
    "\n",
    "    #filestems_type\n",
    "    filestems=[x for x in filestems if x.startswith(result)]\n",
    "    \n",
    "    #nobs\n",
    "    nobs=len(filestems)\n",
    "\n",
    "    #tot\n",
    "    tot=nobs-1\n",
    "  \n",
    "    #ordered\n",
    "    frames=[None]*nobs\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"PRIMARYID\", #Unique number for identifying a FAERS report\n",
    "        \"CASEID\", #Number for identifying a FAERS case\n",
    "        \"CASEVERSION\", #Safety Report Version Number\n",
    "        \"I_F_CODE\", #Code for initial or follow-up status of report\n",
    "        \"EVENT_DT\", #Date the adverse event occurred or began\n",
    "        \"MFR_DT\", #Date manufacturer first received initial information\n",
    "        \"INIT_FDA_DT\", #Date FDA received first version\n",
    "        \"FDA_DT\", #Date FDA received Case\n",
    "        \"REPT_COD\", #report type: \"EXP\" Expedited (15-Day), \"PER\" Periodic (Non-Expedited), \"DIR\" Direct, \"5DAY\" 5-Day, \"30DAY\" 30-Day\n",
    "        \"AUTH_NUM\", #Regulatory Authority’s case report number\n",
    "        \"MFR_NUM\", #Manufacturer's unique report identifier\n",
    "        \"MFR_SNDR\", #Coded name of manufacturer sending report\n",
    "        \"LIT_REF\", #Literature Reference information\n",
    "        \"AGE\", #patient's age at event\n",
    "        \"AGE_COD\", #Unit abbreviation for patient's age: \"DEC\" DECADE, \"YR\" YEAR, \"MON\" MONTH, \"WK\" WEEK, \"DY\" DAY, \"HR\" HOUR\n",
    "        \"AGE_GRP\", #Patient Age Group code: \"N\" Neonate, \"I\" Infant, \"C\" Child, \"T\" Adolescent, \"A\" Adult, \"E\" Elderly\n",
    "        \"SEX\", # patient's sex: \"UNK\" Unknown, \"M\" Male, \"F\" Female\n",
    "        \"E_SUB\", #Whether (Y/N) this report was submitted under the electronic submissions\n",
    "        \"WT\", #patient's weight\n",
    "        \"WT_COD\", #Unit abbreviation for patient's weight: \"KG\" Kilograms, \"LBS\" Pounds, \"GMS\" Grams\n",
    "        \"REPT_DT\", #Date report was sent (YYYYMMDD format)\n",
    "        \"TO_MFR\", #Whether (Y/N) voluntary reporter also notified manufacturer\n",
    "        \"OCCP_COD\", #reporter's type of occupation: \"MD\" Physician, \"PH\" Pharmacist, \"OT\" Other health-professional, \"LW\" Lawyer, \"CN\" Consumer\n",
    "        \"REPORTER_COUNTRY\", #country of the reporter: https://evs.nci.nih.gov/ftp1/GENC/NCIt-GENC_Terminology.txt\n",
    "        \"OCCR_COUNTRY\", #country where the event occurred\n",
    "        ]\n",
    "    \n",
    "    #excludebefore2014\n",
    "    excludebefore2014=[\n",
    "        \"AUTH_NUM\",\n",
    "        \"LIT_REF\",\n",
    "        \"AGE_GRP\",\n",
    "        ]\n",
    "    \n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"PRIMARYID\",\n",
    "        ]\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"PRIMARYID\",\n",
    "        ]\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"PRIMARYID\",\n",
    "        \"CASEID\",\n",
    "        \"CASEVERSION\",\n",
    "        \"I_F_CODE\",\n",
    "        \"EVENT_DT\",\n",
    "        \"MFR_DT\",\n",
    "        \"INIT_FDA_DT\",\n",
    "        \"FDA_DT\",\n",
    "        \"REPT_COD\",\n",
    "        \"AUTH_NUM\",\n",
    "        \"MFR_NUM\",\n",
    "        \"MFR_SNDR\",\n",
    "        \"LIT_REF\",\n",
    "        \"AGE\",\n",
    "        \"AGE_COD\",\n",
    "        \"AGE_GRP\",\n",
    "        \"SEX\",\n",
    "        \"E_SUB\",\n",
    "        \"WT\",\n",
    "        \"WT_COD\",\n",
    "        \"REPT_DT\",\n",
    "        \"TO_MFR\",\n",
    "        \"OCCP_COD\",\n",
    "        \"REPORTER_COUNTRY\",\n",
    "        \"OCCR_COUNTRY\",\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        ]\n",
    "\n",
    "    #for\n",
    "    for i, filestem in enumerate(filestems):\n",
    "            \n",
    "        #year\n",
    "        year=int(f\"20{filestem[-4:-2]}\")\n",
    "\n",
    "        #quarter\n",
    "        quarter=int(filestem[-1:])\n",
    "\n",
    "        #if\n",
    "        if year<=2014 and quarter<=2:\n",
    "\n",
    "            #usecols\n",
    "            usecols=[x for x in usecols if x not in excludebefore2014]\n",
    "\n",
    "        #output_path\n",
    "        output_path=Path(f\"{cleanresults}/{filestem}.txt\")\n",
    "\n",
    "        #if\n",
    "        if output_path.is_file():\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{cleanresults}/{filestem}.csv\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=1000,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "\n",
    "            #print\n",
    "            print(f\"{i} - {filestem} - already done\")\n",
    "\n",
    "        #elif\n",
    "        elif not output_path.is_file():\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{rawresults}/{filestem}.txt\"\n",
    "            sep=\"$\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                #usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                nrows=1000,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "            \n",
    "            #upper\n",
    "            list_columns=list(df_i.columns)\n",
    "            df_i.columns=[x.upper() for x in list_columns]\n",
    "\n",
    "            #usecols\n",
    "            df_i=df_i[usecols]\n",
    "            \n",
    "            #lowercase\n",
    "            df_i=_lowercase(df_i)\n",
    "\n",
    "            #dropna\n",
    "            df_i=df_i.dropna(subset=dropna_cols)\n",
    "\n",
    "            #year\n",
    "            df_i[\"year\"]=year\n",
    "\n",
    "            #quarter\n",
    "            df_i[\"quarter\"]=quarter\n",
    "\n",
    "            #sortvalues\n",
    "            df_i=df_i.sort_values(\n",
    "                by=sortvalues_cols,\n",
    "                )\n",
    "\n",
    "            #ordered\n",
    "            df_i=df_i[ordered_cols]\n",
    "\n",
    "            #to_csv\n",
    "            filepath=f\"{cleanresults}/{filestem}.csv\"\n",
    "            df_i.to_csv(filepath, index=False) \n",
    "\n",
    "            #print\n",
    "            print(f\"{i}/{tot} - {filestem} - done\")\n",
    "\n",
    "        #frames\n",
    "        frames[i]=df_i\n",
    "\n",
    "    #concat\n",
    "    df=pd.concat(frames)\n",
    "\n",
    "    #sortvalues\n",
    "\n",
    "    #ordered\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False) \n",
    "    #'''\n",
    "#_faers_demo(folders, items)\n",
    "\n",
    "\n",
    "#_faers_drug\n",
    "#https://fis.fda.gov/extensions/FPD-QDE-FAERS/FPD-QDE-FAERS.html\n",
    "folders=[\"ciani/data/faers\", \"ciani/_faers\"]\n",
    "items=[\"drug\"]\n",
    "def _faers_drug(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    result=items[0]\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"\n",
    "\n",
    "    #cleanresults\n",
    "    cleanresults=f\"{results}/clean\"\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems = _folder_to_filestems(rawresults)\n",
    "\n",
    "    #filestems_type\n",
    "    filestems=[x for x in filestems if x.startswith(result)]\n",
    "    \n",
    "    #nobs\n",
    "    nobs=len(filestems)\n",
    "\n",
    "    #tot\n",
    "    tot=nobs-1\n",
    "  \n",
    "    #ordered\n",
    "    frames=[None]*nobs\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"PRIMARYID\", #Unique number for identifying a FAERS report\n",
    "        \"CASEID\", #Number for identifying a FAERS case\n",
    "        \"DRUG_SEQ\", #Unique number for identifying a drug for a Case\n",
    "        \"ROLE_COD\", #drug's reported role in event: \"PS\" Primary Suspect Drug, \"SS\" Secondary Suspect Drug, \"C\" Concomitant, \"I\" Interacting\n",
    "        \"DRUGNAME\", #Name of medicinal product\n",
    "        \"PROD_AI\", #Product Active Ingredient\n",
    "        \"VAL_VBM\", #source of DRUGNAME: \"1\" Validated trade name used, \"2\" Verbatim name used\n",
    "        \"ROUTE\", #The route of drug administration\n",
    "        \"DOSE_VBM\", #Verbatim text for dose, frequency, and route\n",
    "        \"CUM_DOSE_CHR\", #Cumulative dose to first reaction\n",
    "        \"CUM_DOSE_UNIT\", #Cumulative dose to first reaction unit\n",
    "        \"DECHAL\", #reaction abated when drug therapy was stopped: \"Y\" Positive dechallenge, \"N\" Negative dechallenge, \"U\" Unknown, \"D\" Does not apply\n",
    "        \"RECHAL\", #reaction recurred when drug therapy was restarted: \"Y\" Positive rechallenge, \"N\" Negative rechallenge, \"U\" Unknown, \"D\" Does not apply\n",
    "        \"LOT_NUM\", #Lot number of the drug\n",
    "        \"EXP_DT\", #Expiration date of the drug\n",
    "        \"NDA_NUM\", #NDA number\n",
    "        \"DOSE_AMT\", #Amount of drug reported\n",
    "        \"DOSE_UNIT\", #Unit of drug dose\n",
    "        \"DOSE_FORM\", #Form of dose reported\n",
    "        \"DOSE_FREQ\", #Code for Frequency\n",
    "        ]\n",
    "    \n",
    "    #excludebefore2014\n",
    "    excludebefore2014=[\n",
    "        \"PROD_AI\",\n",
    "        ]\n",
    "    \n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"PRIMARYID\",\n",
    "        ]\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"PRIMARYID\",\n",
    "        \"DRUG_SEQ\",\n",
    "        ]\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"PRIMARYID\",\n",
    "        \"CASEID\",\n",
    "        \"DRUG_SEQ\",\n",
    "        \"ROLE_COD\",\n",
    "        \"DRUGNAME\",\n",
    "        \"PROD_AI\",\n",
    "        \"VAL_VBM\",\n",
    "        \"ROUTE\",\n",
    "        \"DOSE_VBM\",\n",
    "        \"CUM_DOSE_CHR\",\n",
    "        \"CUM_DOSE_UNIT\",\n",
    "        \"DECHAL\",\n",
    "        \"RECHAL\",\n",
    "        \"LOT_NUM\",\n",
    "        \"EXP_DT\",\n",
    "        \"NDA_NUM\",\n",
    "        \"DOSE_AMT\",\n",
    "        \"DOSE_UNIT\",\n",
    "        \"DOSE_FORM\",\n",
    "        \"DOSE_FREQ\",\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        ]\n",
    "\n",
    "    #for\n",
    "    for i, filestem in enumerate(filestems):\n",
    "            \n",
    "        #year\n",
    "        year=int(f\"20{filestem[-4:-2]}\")\n",
    "\n",
    "        #quarter\n",
    "        quarter=int(filestem[-1:])\n",
    "\n",
    "        #if\n",
    "        if year<=2014 and quarter<=2:\n",
    "\n",
    "            #usecols\n",
    "            usecols=[x for x in usecols if x not in excludebefore2014]\n",
    "\n",
    "        #output_path\n",
    "        output_path=Path(f\"{cleanresults}/{filestem}.txt\")\n",
    "\n",
    "        #if\n",
    "        if output_path.is_file():\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{cleanresults}/{filestem}.csv\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                nrows=1000,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "\n",
    "            #print\n",
    "            print(f\"{i} - {filestem} - already done\")\n",
    "\n",
    "        #elif\n",
    "        elif not output_path.is_file():\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{rawresults}/{filestem}.txt\"\n",
    "            sep=\"$\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                #usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=1000,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "            \n",
    "            #upper\n",
    "            list_columns=list(df_i.columns)\n",
    "            df_i.columns=[x.upper() for x in list_columns]\n",
    "\n",
    "            #usecols\n",
    "            df_i=df_i[usecols]\n",
    "            \n",
    "            #lowercase\n",
    "            df_i=_lowercase(df_i)\n",
    "\n",
    "            #dropna\n",
    "            df_i=df_i.dropna(subset=dropna_cols)\n",
    "\n",
    "            #year\n",
    "            df_i[\"year\"]=year\n",
    "\n",
    "            #quarter\n",
    "            df_i[\"quarter\"]=quarter\n",
    "\n",
    "            #sortvalues\n",
    "            df_i=df_i.sort_values(\n",
    "                by=sortvalues_cols,\n",
    "                )\n",
    "\n",
    "            #ordered\n",
    "            df_i=df_i[ordered_cols]\n",
    "\n",
    "            #to_csv\n",
    "            filepath=f\"{cleanresults}/{filestem}.csv\"\n",
    "            df_i.to_csv(filepath, index=False) \n",
    "\n",
    "            #print\n",
    "            print(f\"{i}/{tot} - {filestem} - done\")\n",
    "\n",
    "        #frames\n",
    "        frames[i]=df_i\n",
    "\n",
    "    #concat\n",
    "    df=pd.concat(frames)\n",
    "\n",
    "    #sortvalues\n",
    "\n",
    "    #ordered\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False) \n",
    "    #'''\n",
    "#_faers_drug(folders, items)\n",
    "\n",
    "\n",
    "#_faers_outc\n",
    "#https://fis.fda.gov/extensions/FPD-QDE-FAERS/FPD-QDE-FAERS.html\n",
    "folders=[\"ciani/data/faers\", \"ciani/_faers\"]\n",
    "items=[\"outc\"]\n",
    "def _faers_outc(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    result=items[0]\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"\n",
    "\n",
    "    #cleanresults\n",
    "    cleanresults=f\"{results}/clean\"\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems = _folder_to_filestems(rawresults)\n",
    "\n",
    "    #filestems_type\n",
    "    filestems=[x for x in filestems if x.startswith(result)]\n",
    "    \n",
    "    #nobs\n",
    "    nobs=len(filestems)\n",
    "\n",
    "    #tot\n",
    "    tot=nobs-1\n",
    "  \n",
    "    #ordered\n",
    "    frames=[None]*nobs\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"PRIMARYID\", #Unique number for identifying a FAERS report\n",
    "        \"CASEID\", #Number for identifying a FAERS case\n",
    "        \"OUTC_COD\", #patient outcome: \"DE\" Death, \"LT\" Life-Threatening, \"HO\" Hospitalization, \"DS\" Disability, \"CA\" Congenital Anomaly, \"RI\" Required Intervention, \"OT\" Other Serious     \n",
    "        ]\n",
    "    \n",
    "    #excludebefore2014\n",
    "    excludebefore2014=[\n",
    "        ]\n",
    "    \n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"PRIMARYID\",\n",
    "        ]\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"PRIMARYID\",\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        ]\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"PRIMARYID\",\n",
    "        \"CASEID\",\n",
    "        \"OUTC_COD\",\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        ]\n",
    "\n",
    "    #for\n",
    "    for i, filestem in enumerate(filestems):\n",
    "            \n",
    "        #year\n",
    "        year=int(f\"20{filestem[-4:-2]}\")\n",
    "\n",
    "        #quarter\n",
    "        quarter=int(filestem[-1:])\n",
    "\n",
    "        #if\n",
    "        if year<=2014 and quarter<=2:\n",
    "\n",
    "            #usecols\n",
    "            usecols=[x for x in usecols if x not in excludebefore2014]\n",
    "\n",
    "        #output_path\n",
    "        output_path=Path(f\"{cleanresults}/{filestem}.txt\")\n",
    "\n",
    "        #if\n",
    "        if output_path.is_file():\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{cleanresults}/{filestem}.csv\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=1000,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "\n",
    "            #print\n",
    "            print(f\"{i} - {filestem} - already done\")\n",
    "\n",
    "        #elif\n",
    "        elif not output_path.is_file():\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{rawresults}/{filestem}.txt\"\n",
    "            sep=\"$\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                #usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=1000,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "            \n",
    "            #upper\n",
    "            list_columns=list(df_i.columns)\n",
    "            df_i.columns=[x.upper() for x in list_columns]\n",
    "\n",
    "            #usecols\n",
    "            df_i=df_i[usecols]\n",
    "            \n",
    "            #lowercase\n",
    "            df_i=_lowercase(df_i)\n",
    "\n",
    "            #dropna\n",
    "            df_i=df_i.dropna(subset=dropna_cols)\n",
    "\n",
    "            #year\n",
    "            df_i[\"year\"]=year\n",
    "\n",
    "            #quarter\n",
    "            df_i[\"quarter\"]=quarter\n",
    "\n",
    "            #sortvalues\n",
    "            df_i=df_i.sort_values(\n",
    "                by=sortvalues_cols,\n",
    "                )\n",
    "\n",
    "            #ordered\n",
    "            df_i=df_i[ordered_cols]\n",
    "\n",
    "            #to_csv\n",
    "            filepath=f\"{cleanresults}/{filestem}.csv\"\n",
    "            df_i.to_csv(filepath, index=False) \n",
    "\n",
    "            #print\n",
    "            print(f\"{i}/{tot} - {filestem} - done\")\n",
    "\n",
    "        #frames\n",
    "        frames[i]=df_i\n",
    "\n",
    "    #concat\n",
    "    df=pd.concat(frames)\n",
    "\n",
    "    #sortvalues\n",
    "\n",
    "    #ordered\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False) \n",
    "    #'''\n",
    "#_faers_outc(folders, items)\n",
    "\n",
    "\n",
    "#_whoatc\n",
    "#https://www.whocc.no/atc_ddd_index/\n",
    "#https://www.whocc.no/filearchive/publications/2023_guidelines_web.pdf\n",
    "folders=[\"ciani/data/whoatc\", \"ciani/_whoatc\"]\n",
    "items=[\"2023 ATC Index with DDDs_electronic version\", \"whoatc\"]\n",
    "atccodes=(\"a10a\", \"a10b\")\n",
    "def _whoatc(folders, items, atccode):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"ATC code\",\n",
    "        \"ATC level name\",\n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.csv\"\n",
    "    sep=\",\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=10,\n",
    "        #encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        )\n",
    "    \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"ATC code\",\n",
    "        \"ATC level name\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"ATC code\"].apply(len)==7]\n",
    "\n",
    "    #sortvalues\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"ATC code\",\n",
    "        \"ATC level name\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False) \n",
    "\n",
    "    #startswith\n",
    "    df=df[df[\"ATC code\"].str.startswith(atccodes)] \n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}_atccodes.csv\"\n",
    "    df.to_csv(filepath, index=False) \n",
    "\n",
    "    #tolist\n",
    "    values_tolist=df[\"ATC level name\"].tolist()\n",
    "\n",
    "    #set\n",
    "    atclevelnames=set(values_tolist)\n",
    "\n",
    "    #return\n",
    "    return atclevelnames \n",
    "    #'''\n",
    "#_whoatc(folders, items, atccodes)\n",
    "\n",
    "\n",
    "#_medicarepartd\n",
    "#https://data.cms.gov/provider-summary-by-type-of-service/medicare-part-d-prescribers/medicare-part-d-prescribers-by-provider-and-drug\n",
    "#https://data.cms.gov/resources/medicare-part-d-prescribers-by-provider-and-drug-data-dictionary\n",
    "#https://data.cms.gov/provider-characteristics/medicare-provider-supplier-enrollment/medicare-provider-and-supplier-taxonomy-crosswalk\n",
    "folders=[\"ciani/data/medicarepartd\", \"ciani/_medicarepartd\"]\n",
    "items=[\"medicarepartd\"]\n",
    "def _medicarepartd(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    result=items[0]\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems =_folder_to_filestems(resources)\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(filestems)\n",
    "\n",
    "    #ordered\n",
    "    frames=[None]*nobs\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"Prscrbr_NPI\",\n",
    "        \"Prscrbr_City\",\n",
    "        \"Prscrbr_State_Abrvtn\",\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Tot_Clms\",\n",
    "        #\"Tot_Day_Suply\",\n",
    "        \"Tot_Drug_Cst\",\n",
    "        #\"Tot_Benes\",\n",
    "        ]\n",
    "    \n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"Prscrbr_NPI\",\n",
    "        \"Prscrbr_City\",\n",
    "        \"Prscrbr_State_Abrvtn\",\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Tot_Clms\",\n",
    "        #\"Tot_Day_Suply\",\n",
    "        \"Tot_Drug_Cst\",\n",
    "        #\"Tot_Benes\",\n",
    "        ]\n",
    "\n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"Prscrbr_NPI\",\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        ]\n",
    "    \n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"Prscrbr_NPI\",\n",
    "        \"Prscrbr_City\",\n",
    "        \"Prscrbr_State_Abrvtn\",\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Tot_Clms\",\n",
    "        #\"Tot_Day_Suply\",\n",
    "        \"Tot_Drug_Cst\",\n",
    "        #\"Tot_Benes\",\n",
    "        \"statename\",\n",
    "        \"year\",\n",
    "        ]\n",
    "\n",
    "    #_whoatc\n",
    "    folders=[\"ciani/data/whoatc\", \"ciani/_whoatc\"]\n",
    "    items=[\"2023 ATC Index with DDDs_electronic version\", \"whoatc\"]\n",
    "    atccodes=(\"a10a\", \"a10b\")\n",
    "    atclevelnames=_whoatc(folders, items, atccodes)\n",
    "\n",
    "    #for\n",
    "    for i, filestem in enumerate(filestems):\n",
    "\n",
    "        #year\n",
    "        twodigityear = filestem[(filestem.find(\"DY\") + 2) : (filestem.find(\"DY\")+ 4)]\n",
    "        year=int(f\"20{twodigityear}\")\n",
    "\n",
    "        #rawfile\n",
    "        rawfile=f\"{rawresults}/{year}.csv\"\n",
    "        \n",
    "        #output_path\n",
    "        output_path=Path(rawfile)\n",
    "\n",
    "        #if\n",
    "        if output_path.is_file():\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{rawfile}\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                #usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=1000,\n",
    "                encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "\n",
    "            #print\n",
    "            print(f\"{i} - {filestem} - already done\")\n",
    "\n",
    "        #elif\n",
    "        elif not output_path.is_file():\n",
    "\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{resources}/{filestem}.csv\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=1000,\n",
    "                encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "            \n",
    "            #lowercase\n",
    "            df_i=_lowercase(df_i)\n",
    "\n",
    "            #dropna\n",
    "            df_i=df_i.dropna(subset=dropna_cols)\n",
    "\n",
    "            #dropobs\n",
    "            df_i=df_i[df_i[\"Gnrc_Name\"].isin(atclevelnames)]\n",
    "\n",
    "            #statename\n",
    "            df_i[\"statename\"]=df_i[\"Prscrbr_State_Abrvtn\"].replace(statenames_dict)\n",
    "\n",
    "            #year\n",
    "            df_i[\"year\"]=year\n",
    "\n",
    "            #sortvalues\n",
    "            df_i=df_i.sort_values(\n",
    "                by=sortvalues_cols,\n",
    "                )\n",
    "\n",
    "            #ordered\n",
    "            df_i=df_i[ordered_cols]\n",
    "\n",
    "            #to_csv\n",
    "            filepath=f\"{rawfile}\"\n",
    "            df_i.to_csv(filepath, index=False)\n",
    "\n",
    "            #print\n",
    "            print(f\"{i} - {filestem} - done\")\n",
    "\n",
    "        #frames\n",
    "        frames[i]=df_i\n",
    "\n",
    "    #concat\n",
    "    df=pd.concat(frames)\n",
    "\n",
    "    #sortvalues\n",
    "    \n",
    "    #ordered\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_medicarepartd(folders, items)\n",
    "\n",
    "\n",
    "#_cmsndf\n",
    "#https://data.cms.gov/provider-data/dataset/mj5m-pzi6\n",
    "folders=[\"ciani/data/cmsndf\", \"ciani/_cmsndf\"]\n",
    "items=[\"DAC_NationalDownloadableFile\", \"cmsndf\"]\n",
    "def _cmsndf(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"NPI\",\n",
    "        \"adr_ln_1\",\n",
    "        \"City/Town\",\n",
    "        \"State\",\n",
    "        \"ZIP Code\",\n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.csv\"\n",
    "    sep=\",\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=10,\n",
    "        #encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        )\n",
    "    \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"NPI\",\n",
    "        \"adr_ln_1\",\n",
    "        \"City/Town\",\n",
    "        \"State\",\n",
    "        \"ZIP Code\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #dropobs\n",
    "\n",
    "    #dropdups\n",
    "    dropdups_cols=[\n",
    "        \"NPI\",\n",
    "        \"City/Town\",\n",
    "        \"State\",\n",
    "        ]\n",
    "    df=df.drop_duplicates(subset=dropdups_cols)\n",
    "    \n",
    "    #zipcode\n",
    "    df[\"zipcode\"]=df[\"ZIP Code\"].str[0:5]\n",
    "\n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"NPI\",\n",
    "        \"State\",\n",
    "        \"City/Town\", \n",
    "        ]\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"NPI\",\n",
    "        \"adr_ln_1\",\n",
    "        \"City/Town\",\n",
    "        \"State\",\n",
    "        \"zipcode\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_cmsndf(folders, items)\n",
    "\n",
    "\n",
    "#_medicarelandscapepdp\n",
    "#https://www.cms.gov/medicare/coverage/prescription-drug-coverage\n",
    "folders=[\"ciani/data/medicarelandscapepdp\", \"ciani/_medicarelandscapepdp\"]\n",
    "items=[\"medicarelandscapepdp\"]\n",
    "def _medicarelandscapepdp(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    result=items[0]\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"    \n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"State\",\n",
    "        \"Monthly Drug Premium\",\n",
    "        \"Annual Drug Deductible\",\n",
    "        \"Contract ID\",\n",
    "        \"Plan ID\",\n",
    "        ]\n",
    "    \n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"State\",\n",
    "        \"Contract ID\",\n",
    "        \"Plan ID\",\n",
    "        ]\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"State\",\n",
    "        \"Contract ID\",\n",
    "        \"Plan ID\",\n",
    "        ]\n",
    "    \n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"State\",\n",
    "        \"Monthly Drug Premium\",\n",
    "        \"Annual Drug Deductible\",\n",
    "        \"Contract ID\",\n",
    "        \"Plan ID\",\n",
    "        \"year\",\n",
    "        ]\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems =_folder_to_filestems(resources)\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(filestems)\n",
    "\n",
    "    #ordered\n",
    "    frames=[None]*nobs\n",
    "\n",
    "    #for\n",
    "    for i, filestem in enumerate(filestems):\n",
    "\n",
    "        #filepath\n",
    "        filepath=f\"{resources}/{filestem}.csv\"\n",
    "\n",
    "        #rawfile\n",
    "        rawfile=f\"{rawresults}/{filestem}.csv\"\n",
    "\n",
    "        #year\n",
    "        year=int(filestem[0:4])\n",
    "    \n",
    "        #read_csv\n",
    "        sep=\",\"\n",
    "        df_i=pd.read_csv(\n",
    "            filepath, \n",
    "            sep=sep,\n",
    "            header=3,\n",
    "            usecols=usecols,\n",
    "            dtype=\"string\",\n",
    "            #nrows=10,\n",
    "            encoding=\"latin-1\",\n",
    "            #on_bad_lines=\"skip\",\n",
    "            )\n",
    "            \n",
    "        #lowercase\n",
    "        df_i=_lowercase(df_i)\n",
    "\n",
    "        #dropna\n",
    "        df_i=df_i.dropna(subset=dropna_cols)\n",
    "\n",
    "        #dropobs\n",
    "\n",
    "        #replace\n",
    "        replace_cols=[\n",
    "            \"Monthly Drug Premium\",\n",
    "            \"Annual Drug Deductible\",\n",
    "            ]\n",
    "        for j, col in enumerate(replace_cols):\n",
    "            df_i[col]=df_i[col].str.strip()\n",
    "            df_i[col]=df_i[col].str.replace(\"$\", \"\")\n",
    "            df_i[col]=df_i[col].str.replace(\"-\", \"0\")\n",
    "\n",
    "        #year\n",
    "        df_i[\"year\"]=year\n",
    "\n",
    "        #sortvalues\n",
    "        df_i=df_i.sort_values(\n",
    "            by=sortvalues_cols,\n",
    "            )\n",
    "\n",
    "        #ordered\n",
    "        df_i=df_i[ordered_cols]\n",
    "\n",
    "        #to_csv\n",
    "        filepath=f\"{rawfile}\"\n",
    "        df_i.to_csv(filepath, index=False)\n",
    "\n",
    "        #frames\n",
    "        frames[i]=df_i\n",
    "\n",
    "        #print\n",
    "        print(f\"{i} - {filestem} - done\")\n",
    "\n",
    "    #concat\n",
    "    df=pd.concat(frames)\n",
    "\n",
    "    #sortvalues\n",
    "    \n",
    "    #ordered\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_medicarelandscapepdp(folders, items)\n",
    "\n",
    "\n",
    "#_medicarelandscapema\n",
    "#https://www.cms.gov/medicare/coverage/prescription-drug-coverage\n",
    "folders=[\"ciani/data/medicarelandscapema\", \"ciani/_medicarelandscapema\"]\n",
    "items=[\"medicarelandscapema\"]\n",
    "def _medicarelandscapema(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    result=items[0]\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"    \n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"State\",\n",
    "        \"County\",\n",
    "        \"Monthly Consolidated Premium (Includes Part C + D)\",\n",
    "        \"Annual Drug Deductible\",\n",
    "        \"Drug Benefit Type\",\n",
    "        \"Contract ID\",\n",
    "        \"Plan ID\",\n",
    "        ]\n",
    "    \n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"State\",\n",
    "        \"County\",\n",
    "        \"Contract ID\",\n",
    "        \"Plan ID\",\n",
    "        ]\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"State\",\n",
    "        \"County\",\n",
    "        \"Contract ID\",\n",
    "        \"Plan ID\",\n",
    "        \"year\",\n",
    "        ]\n",
    "    \n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"State\",\n",
    "        \"County\",\n",
    "        \"Monthly Consolidated Premium (Includes Part C + D)\",\n",
    "        \"Annual Drug Deductible\",\n",
    "        \"Drug Benefit Type\",\n",
    "        \"Contract ID\",\n",
    "        \"Plan ID\",\n",
    "        \"year\",\n",
    "        ]\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems =_folder_to_filestems(resources)\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(filestems)\n",
    "\n",
    "    #ordered\n",
    "    frames=[None]*nobs\n",
    "\n",
    "    #for\n",
    "    for i, filestem in enumerate(filestems):\n",
    "\n",
    "        #filepath\n",
    "        filepath=f\"{resources}/{filestem}.csv\"\n",
    "\n",
    "        #rawfile\n",
    "        rawfile=f\"{rawresults}/{filestem}.csv\"\n",
    "    \n",
    "        #read_csv\n",
    "        sep=\",\"\n",
    "        df_i=pd.read_csv(\n",
    "            filepath, \n",
    "            sep=sep,\n",
    "            header=5,\n",
    "            #usecols=usecols,\n",
    "            dtype=\"string\",\n",
    "            #nrows=10,\n",
    "            encoding=\"latin-1\",\n",
    "            #on_bad_lines=\"skip\",\n",
    "            )\n",
    "        \n",
    "        #strip\n",
    "        df_i.columns=df_i.columns.str.strip()\n",
    "\n",
    "        #replace\n",
    "        df_i.columns=df_i.columns.str.replace(\"\\n\", \"\")\n",
    "          \n",
    "        #usecols\n",
    "        df_i=df_i[usecols]\n",
    "        \n",
    "        #lowercase\n",
    "        df_i=_lowercase(df_i)\n",
    "\n",
    "        #dropna\n",
    "        df_i=df_i.dropna(subset=dropna_cols)\n",
    "\n",
    "        #dropobs\n",
    "        df_i=df_i[df_i[\"Annual Drug Deductible\"].notna()]\n",
    "\n",
    "        #replace\n",
    "        replace_cols=[\n",
    "            \"Monthly Consolidated Premium (Includes Part C + D)\",\n",
    "            \"Annual Drug Deductible\",\n",
    "            ]\n",
    "        for j, col in enumerate(replace_cols):\n",
    "            df_i[col]=df_i[col].str.strip()\n",
    "            df_i[col]=df_i[col].str.replace(\"$\", \"\")\n",
    "            df_i[col]=df_i[col].str.replace(\"-\", \"0\")\n",
    "\n",
    "        #year\n",
    "        year=int(filestem[0:4])\n",
    "        df_i[\"year\"]=year\n",
    "\n",
    "        #sortvalues\n",
    "        df_i=df_i.sort_values(\n",
    "            by=sortvalues_cols,\n",
    "            )\n",
    "\n",
    "        #ordered\n",
    "        df_i=df_i[ordered_cols]\n",
    "\n",
    "        #to_csv\n",
    "        filepath=f\"{rawfile}\"\n",
    "        df_i.to_csv(filepath, index=False)\n",
    "\n",
    "        #frames\n",
    "        frames[i]=df_i\n",
    "\n",
    "        #print\n",
    "        print(f\"{i} - {filestem} - done\")\n",
    "\n",
    "    #concat\n",
    "    df=pd.concat(frames)\n",
    "\n",
    "    #sortvalues\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "    \n",
    "    #ordered\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_medicarelandscapema(folders, items)\n",
    "\n",
    "\n",
    "#_medicareenrollmentpdp\n",
    "#https://www.cms.gov/data-research/statistics-trends-and-reports/medicare-advantagepart-d-contract-and-enrollment-data/monthly-pdp-enrollment-state/county/contract\n",
    "folders=[\"ciani/data/medicareenrollmentpdp\", \"ciani/_medicareenrollmentpdp\"]\n",
    "items=[\"medicareenrollmentpdp\"]\n",
    "def _medicareenrollmentpdp(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    result=items[0]\n",
    "\n",
    "    #zipresults\n",
    "    zipresults=f\"{results}/zip\"\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"\n",
    "\n",
    "    #cleanresults\n",
    "    cleanresults=f\"{results}/clean\"\n",
    "\n",
    "    #lenstem\n",
    "    lenstem=len(\"SCC_Enrollment_PDP_\")\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems = _folder_to_filestems(resources)\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(filestems)\n",
    "\n",
    "    #tot\n",
    "    tot=nobs-1\n",
    "\n",
    "    #ordered\n",
    "    frames=[None]*nobs\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"Contract ID\",\n",
    "        \"FIPS Code\",\n",
    "        \"Enrolled\",\n",
    "        ]\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"Contract ID\",\n",
    "        \"FIPS Code\",\n",
    "        \"Enrolled\",\n",
    "        ]\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"FIPS Code\",\n",
    "        \"Contract ID\",\n",
    "        \"Enrolled\",\n",
    "        ]\n",
    "    \n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"Contract ID\",\n",
    "        \"FIPS Code\",\n",
    "        \"Enrolled\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        ]\n",
    "\n",
    "    #for\n",
    "    for i, filestem in enumerate(filestems):\n",
    "\n",
    "        #zipfile\n",
    "        zipfile=f\"{resources}/{filestem}.zip\"\n",
    "\n",
    "        #year\n",
    "        year=filestem[(lenstem):(lenstem+4)]\n",
    "\n",
    "        #month\n",
    "        month=filestem[(lenstem+5):(lenstem+5+2)]\n",
    "\n",
    "        #rawfile\n",
    "        rawfile=f\"{rawresults}/{year}_{month}.csv\"\n",
    "\n",
    "        #cleanfile\n",
    "        cleanfile=f\"{cleanresults}/{year}_{month}.csv\"\n",
    "\n",
    "        #output_path\n",
    "        output_path=Path(rawfile)\n",
    "\n",
    "        #if\n",
    "        if output_path.is_file():\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{cleanfile}\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=10,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "\n",
    "            #print\n",
    "            print(f\"{i}/{tot} - {filestem} - already done\") \n",
    "\n",
    "        #elif\n",
    "        elif not output_path.is_file():\n",
    "\n",
    "            #ZipFile\n",
    "            with ZipFile(zipfile, \"r\") as zip_ref:\n",
    "\n",
    "                #namelist\n",
    "                namelist=zip_ref.namelist()\n",
    "\n",
    "                #tempfile\n",
    "                tempfile=[x for x in namelist if x.endswith(\".csv\")][0]\n",
    "                \n",
    "                #extract\n",
    "                zip_ref.extract(tempfile, zipresults)\n",
    "            \n",
    "            #p\n",
    "            p=Path(f\"{zipresults}/{tempfile}\")\n",
    "\n",
    "            #rename\n",
    "            p.rename(rawfile)\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{rawfile}\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=10,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                ) \n",
    "        \n",
    "            #lowercase\n",
    "            df_i=_lowercase(df_i)\n",
    "\n",
    "            #dropna\n",
    "            df_i=df_i.dropna(subset=dropna_cols)\n",
    "\n",
    "            #dropobs\n",
    "\n",
    "            #year\n",
    "            df_i[\"year\"]=year\n",
    "\n",
    "            #month\n",
    "            df_i[\"month\"]=month\n",
    "\n",
    "            #sortvalues\n",
    "            df_i=df_i.sort_values(\n",
    "                by=sortvalues_cols,\n",
    "                )\n",
    "\n",
    "            #ordered\n",
    "            df_i=df_i[ordered_cols]\n",
    "\n",
    "            #to_csv\n",
    "            filepath=f\"{cleanfile}\"\n",
    "            df_i.to_csv(filepath, index=False)\n",
    "\n",
    "            #frames\n",
    "            frames[i]=df_i\n",
    "\n",
    "            #print\n",
    "            print(f\"{i}/{tot} - {filestem} - done\")  \n",
    "\n",
    "    #concat\n",
    "    df=pd.concat(frames)\n",
    "\n",
    "    #sortvalues\n",
    "    \n",
    "    #ordered\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_medicareenrollmentpdp(folders, items)\n",
    "\n",
    "\n",
    "#_medicarepenetrationpdp\n",
    "#https://www.cms.gov/data-research/statistics-trends-and-reports/medicare-advantagepart-d-contract-and-enrollment-data/pdp-state/county-penetration\n",
    "folders=[\"ciani/data/medicarepenetrationpdp\", \"ciani/_medicarepenetrationpdp\"]\n",
    "items=[\"medicarepenetrationpdp\"]\n",
    "def _medicarepenetrationpdp(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    result=items[0]\n",
    "\n",
    "    #zipresults\n",
    "    zipresults=f\"{results}/zip\"\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"\n",
    "\n",
    "    #cleanresults\n",
    "    cleanresults=f\"{results}/clean\"\n",
    "\n",
    "    #lenstem\n",
    "    lenstem=len(\"State_County_Penetration_PDP_\")\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems = _folder_to_filestems(resources)\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(filestems)\n",
    "\n",
    "    #tot\n",
    "    tot=nobs-1\n",
    "\n",
    "    #ordered\n",
    "    frames=[None]*nobs\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"FIPS\",\n",
    "        \"Eligibles\",\n",
    "        \"Enrolled\",\n",
    "        ]\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"FIPS\",\n",
    "        \"Eligibles\",\n",
    "        \"Enrolled\",\n",
    "        ]\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"FIPS\",\n",
    "        ]\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"FIPS\",\n",
    "        \"Eligibles\",\n",
    "        \"Enrolled\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        ]\n",
    "\n",
    "    #for\n",
    "    for i, filestem in enumerate(filestems):\n",
    "\n",
    "        #zipfile\n",
    "        zipfile=f\"{resources}/{filestem}.zip\"\n",
    "\n",
    "        #year\n",
    "        year=filestem[(lenstem):(lenstem+4)]\n",
    "\n",
    "        #month\n",
    "        month=filestem[(lenstem+5):(lenstem+5+2)]\n",
    "\n",
    "        #rawfile\n",
    "        rawfile=f\"{rawresults}/{year}_{month}.csv\"\n",
    "\n",
    "        #cleanfile\n",
    "        cleanfile=f\"{cleanresults}/{year}_{month}.csv\"\n",
    "\n",
    "        #output_path\n",
    "        output_path=Path(rawfile)\n",
    "\n",
    "        #if\n",
    "        if output_path.is_file():\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{cleanfile}\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=10,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "\n",
    "            #print\n",
    "            print(f\"{i}/{tot} - {filestem} - already done\") \n",
    "\n",
    "        #elif\n",
    "        elif not output_path.is_file():\n",
    "\n",
    "            #ZipFile\n",
    "            with ZipFile(zipfile, \"r\") as zip_ref:\n",
    "\n",
    "                #namelist\n",
    "                namelist=zip_ref.namelist()\n",
    "\n",
    "                #tempfile\n",
    "                tempfile=[x for x in namelist if x.endswith(\".csv\")][0]\n",
    "                \n",
    "                #extract\n",
    "                zip_ref.extract(tempfile, zipresults)\n",
    "            \n",
    "            #p\n",
    "            p=Path(f\"{zipresults}/{tempfile}\")\n",
    "\n",
    "            #rename\n",
    "            p.rename(rawfile)\n",
    "            \n",
    "            #read_csv\n",
    "            filepath=f\"{rawfile}\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=10,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                ) \n",
    "        \n",
    "            #lowercase\n",
    "            df_i=_lowercase(df_i)\n",
    "\n",
    "            #dropna\n",
    "            df_i=df_i.dropna(subset=dropna_cols)\n",
    "\n",
    "            #dropobs\n",
    "\n",
    "            #year\n",
    "            df_i[\"year\"]=year\n",
    "\n",
    "            #month\n",
    "            df_i[\"month\"]=month\n",
    "\n",
    "            #sortvalues\n",
    "            df_i=df_i.sort_values(\n",
    "                by=sortvalues_cols,\n",
    "                )\n",
    "\n",
    "            #ordered\n",
    "            ordered_cols=[\n",
    "                \"FIPS\",\n",
    "                \"Eligibles\",\n",
    "                \"Enrolled\",\n",
    "                \"year\",\n",
    "                \"month\",\n",
    "                ]\n",
    "            df_i=df_i[ordered_cols]\n",
    "\n",
    "            #to_csv\n",
    "            filepath=f\"{cleanfile}\"\n",
    "            df_i.to_csv(filepath, index=False)\n",
    "\n",
    "            #frames\n",
    "            frames[i]=df_i\n",
    "\n",
    "            #print\n",
    "            print(f\"{i}/{tot} - {filestem} - done\")  \n",
    "\n",
    "    #concat\n",
    "    df=pd.concat(frames)\n",
    "\n",
    "    #sortvalues\n",
    "    \n",
    "    #ordered\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_medicarepenetrationpdp(folders, items)\n",
    "\n",
    "\n",
    "#_medicarepartbspending\n",
    "#https://data.cms.gov/summary-statistics-on-use-and-payments/medicare-medicaid-spending-by-drug/medicare-part-b-spending-by-drug\n",
    "folders=[\"ciani/data/medicarepartbspending\", \"ciani/_medicarepartbspending\"]\n",
    "items=[\"DSD_PTB_R22_P07_V10_DYT21_HCPCS\", \"medicarepartbspending\"]\n",
    "def _medicarepartbspending(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"HCPCS_Cd\",\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        #2017\n",
    "        \"Tot_Spndng_2017\",\n",
    "        \"Tot_Dsg_Unts_2017\",\n",
    "        \"Tot_Clms_2017\",\n",
    "        \"Tot_Benes_2017\",\n",
    "        #2018\n",
    "        \"Tot_Spndng_2018\",\n",
    "        \"Tot_Dsg_Unts_2018\",\n",
    "        \"Tot_Clms_2018\",\n",
    "        \"Tot_Benes_2019\",\n",
    "        #2019\n",
    "        \"Tot_Spndng_2019\",\n",
    "        \"Tot_Dsg_Unts_2019\",\n",
    "        \"Tot_Clms_2019\",\n",
    "        \"Tot_Benes_2019\",\n",
    "        #2020\n",
    "        \"Tot_Spndng_2020\",\n",
    "        \"Tot_Dsg_Unts_2020\",\n",
    "        \"Tot_Clms_2020\",\n",
    "        \"Tot_Benes_2020\",\n",
    "        #2021\n",
    "        \"Tot_Spndng_2021\",\n",
    "        \"Tot_Dsg_Unts_2021\",\n",
    "        \"Tot_Clms_2021\",\n",
    "        \"Tot_Benes_2021\",\n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.csv\"\n",
    "    sep=\",\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=10,\n",
    "        #encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        )\n",
    "    \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"HCPCS_Cd\",\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #dropobs\n",
    "\n",
    "    #wide_to_long\n",
    "    stubnames=[\n",
    "        \"Tot_Spndng\",\n",
    "        \"Tot_Dsg_Unts\",\n",
    "        \"Tot_Clms\",\n",
    "        \"Tot_Benes\",\n",
    "        ]\n",
    "    i=[\n",
    "        \"HCPCS_Cd\",\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        ]\n",
    "    j=\"year\"\n",
    "    sep=\"_\"\n",
    "    suffix=r\"\\w+\"\n",
    "    df=pd.wide_to_long(\n",
    "        df,\n",
    "        stubnames=stubnames,\n",
    "        i=i,\n",
    "        j=j,\n",
    "        sep=sep,\n",
    "        suffix=suffix,\n",
    "        )\n",
    "    df=df.reset_index()\n",
    "    \n",
    "    #rename\n",
    "    part=\"b\"\n",
    "    rename_dict={\n",
    "        \"Tot_Spndng\": f\"Tot_Spndng_{part}\",\n",
    "        \"Tot_Dsg_Unts\": f\"Tot_Dsg_Unts_{part}\",\n",
    "        \"Tot_Clms\": f\"Tot_Clms_{part}\",\n",
    "        \"Tot_Benes\": f\"Tot_Benes_{part}\",\n",
    "        }\n",
    "    df=df.rename(columns=rename_dict)\n",
    "\n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"HCPCS_Cd\",\n",
    "        \"year\",\n",
    "        ]\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"HCPCS_Cd\",\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        f\"Tot_Spndng_{part}\",\n",
    "        f\"Tot_Dsg_Unts_{part}\",\n",
    "        f\"Tot_Clms_{part}\",\n",
    "        f\"Tot_Benes_{part}\",\n",
    "        \"year\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_medicarepartbspending(folders, items)\n",
    "\n",
    "\n",
    "#_medicarepartbspending\n",
    "#https://data.cms.gov/summary-statistics-on-use-and-payments/medicare-medicaid-spending-by-drug/medicare-part-d-spending-by-drug\n",
    "folders=[\"ciani/data/medicarepartdspending\", \"ciani/_medicarepartdspending\"]\n",
    "items=[\"DSD_PTD_R22_P04_V22_D21_BGM\", \"medicarepartdspending\"]\n",
    "def _medicarepartdspending(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Tot_Mftr\",\n",
    "        \"Mftr_Name\",\n",
    "        #2017\n",
    "        \"Tot_Spndng_2017\",\n",
    "        \"Tot_Dsg_Unts_2017\",\n",
    "        \"Tot_Clms_2017\",\n",
    "        \"Tot_Benes_2017\",\n",
    "        #2018\n",
    "        \"Tot_Spndng_2018\",\n",
    "        \"Tot_Dsg_Unts_2018\",\n",
    "        \"Tot_Clms_2018\",\n",
    "        \"Tot_Benes_2019\",\n",
    "        #2019\n",
    "        \"Tot_Spndng_2019\",\n",
    "        \"Tot_Dsg_Unts_2019\",\n",
    "        \"Tot_Clms_2019\",\n",
    "        \"Tot_Benes_2019\",\n",
    "        #2020\n",
    "        \"Tot_Spndng_2020\",\n",
    "        \"Tot_Dsg_Unts_2020\",\n",
    "        \"Tot_Clms_2020\",\n",
    "        \"Tot_Benes_2020\",\n",
    "        #2021\n",
    "        \"Tot_Spndng_2021\",\n",
    "        \"Tot_Dsg_Unts_2021\",\n",
    "        \"Tot_Clms_2021\",\n",
    "        \"Tot_Benes_2021\",\n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.csv\"\n",
    "    sep=\",\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=10,\n",
    "        #encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        )\n",
    "    \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Mftr_Name\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #dropobs\n",
    "\n",
    "    #wide_to_long\n",
    "    stubnames=[\n",
    "        \"Tot_Spndng\",\n",
    "        \"Tot_Dsg_Unts\",\n",
    "        \"Tot_Clms\",\n",
    "        \"Tot_Benes\",\n",
    "        ]\n",
    "    i=[\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Mftr_Name\",\n",
    "        ]\n",
    "    j=\"year\"\n",
    "    sep=\"_\"\n",
    "    suffix=r\"\\w+\"\n",
    "    df=pd.wide_to_long(\n",
    "        df,\n",
    "        stubnames=stubnames,\n",
    "        i=i,\n",
    "        j=j,\n",
    "        sep=sep,\n",
    "        suffix=suffix,\n",
    "        )\n",
    "    df=df.reset_index()\n",
    "    \n",
    "    #rename\n",
    "    part=\"d\"\n",
    "    rename_dict={\n",
    "        \"Tot_Spndng\": f\"Tot_Spndng_{part}\",\n",
    "        \"Tot_Dsg_Unts\": f\"Tot_Dsg_Unts_{part}\",\n",
    "        \"Tot_Clms\": f\"Tot_Clms_{part}\",\n",
    "        \"Tot_Benes\": f\"Tot_Benes_{part}\",\n",
    "        }\n",
    "    df=df.rename(columns=rename_dict)\n",
    "    print(df.columns)\n",
    "\n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"Brnd_Name\",\n",
    "        \"Mftr_Name\",\n",
    "        \"year\",\n",
    "        ]\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Tot_Mftr\",\n",
    "        \"Mftr_Name\",\n",
    "        f\"Tot_Spndng_{part}\",\n",
    "        f\"Tot_Dsg_Unts_{part}\",\n",
    "        f\"Tot_Clms_{part}\",\n",
    "        f\"Tot_Benes_{part}\",\n",
    "        \"year\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_medicarepartdspending(folders, items)\n",
    "\n",
    "\n",
    "#_medicaidspending\n",
    "#https://data.cms.gov/summary-statistics-on-use-and-payments/medicare-medicaid-spending-by-drug/medicaid-spending-by-drug\n",
    "folders=[\"ciani/data/medicaidspending\", \"ciani/_medicaidspending\"]\n",
    "items=[\"DSD_MCD_RY24_P06_V20_D22_BGM\", \"medicaidspending\"]\n",
    "def _medicaidspending(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Tot_Mftr\",\n",
    "        \"Mftr_Name\",\n",
    "        #2018\n",
    "        \"Tot_Spndng_2018\",\n",
    "        \"Tot_Dsg_Unts_2018\",\n",
    "        \"Tot_Clms_2018\",\n",
    "        #2019\n",
    "        \"Tot_Spndng_2019\",\n",
    "        \"Tot_Dsg_Unts_2019\",\n",
    "        \"Tot_Clms_2019\",\n",
    "        #2020\n",
    "        \"Tot_Spndng_2020\",\n",
    "        \"Tot_Dsg_Unts_2020\",\n",
    "        \"Tot_Clms_2020\",\n",
    "        #2021\n",
    "        \"Tot_Spndng_2021\",\n",
    "        \"Tot_Dsg_Unts_2021\",\n",
    "        \"Tot_Clms_2021\",\n",
    "        #2022\n",
    "        \"Tot_Spndng_2022\",\n",
    "        \"Tot_Dsg_Unts_2022\",\n",
    "        \"Tot_Clms_2022\",\n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.csv\"\n",
    "    sep=\",\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=10,\n",
    "        #encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        )\n",
    "    \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Mftr_Name\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #dropobs\n",
    "\n",
    "    #wide_to_long\n",
    "    stubnames=[\n",
    "        \"Tot_Spndng\",\n",
    "        \"Tot_Dsg_Unts\",\n",
    "        \"Tot_Clms\",\n",
    "        ]\n",
    "    i=[\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Mftr_Name\",\n",
    "        ]\n",
    "    j=\"year\"\n",
    "    sep=\"_\"\n",
    "    suffix=r\"\\w+\"\n",
    "    df=pd.wide_to_long(\n",
    "        df,\n",
    "        stubnames=stubnames,\n",
    "        i=i,\n",
    "        j=j,\n",
    "        sep=sep,\n",
    "        suffix=suffix,\n",
    "        )\n",
    "    df=df.reset_index()\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"Brnd_Name\",\n",
    "        \"Mftr_Name\",\n",
    "        \"year\",\n",
    "        ]\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        \"Tot_Mftr\",\n",
    "        \"Mftr_Name\",\n",
    "        \"Tot_Spndng\",\n",
    "        \"Tot_Dsg_Unts\",\n",
    "        \"Tot_Clms\",\n",
    "        \"year\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_medicaidspending(folders, items)\n",
    "\n",
    "\n",
    "#_medicarepartbasp\n",
    "#https://www.cms.gov/medicare/payment/fee-for-service-providers/part-b-drugs/average-drug-sales-price\n",
    "#https://www.cms.gov/medicare/payment/all-fee-service-providers/medicare-part-b-drug-average-sales-price/asp-pricing-files\n",
    "folders=[\"ciani/data/medicarepartbasp\", \"ciani/_medicarepartbasp\"]\n",
    "items=[\"medicarepartbasp\"]\n",
    "def _medicarepartbasp(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    result=items[0]\n",
    "\n",
    "    #zipresults\n",
    "    zipresults=f\"{results}/zip\"\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"\n",
    "\n",
    "    #cleanresults\n",
    "    cleanresults=f\"{results}/clean\"\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems = _folder_to_filestems(resources)\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(filestems)\n",
    "\n",
    "    #tot\n",
    "    tot=nobs-1\n",
    "\n",
    "    #ordered\n",
    "    frames=[None]*nobs\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"HCPCS Code\",\n",
    "        \"HCPCS Code Dosage\",\n",
    "        \"Payment Limit\",\n",
    "        ]\n",
    "    \n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"HCPCS Code\",\n",
    "        \"Payment Limit\",\n",
    "        ]\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"HCPCS Code\",\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        ]\n",
    "    \n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"HCPCS Code\",\n",
    "        \"HCPCS Code Dosage\",\n",
    "        \"Payment Limit\",\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        ]\n",
    "\n",
    "    #for\n",
    "    for i, filestem in enumerate(filestems):\n",
    "\n",
    "        #zipfile\n",
    "        zipfile=f\"{resources}/{filestem}.zip\"\n",
    "\n",
    "        #year\n",
    "        year=filestem.split(\"_\")[0]\n",
    "\n",
    "        #month\n",
    "        month=filestem.split(\"_\")[1]\n",
    "\n",
    "        #rawfile\n",
    "        rawfile=f\"{rawresults}/{year}_{month}.csv\"\n",
    "\n",
    "        #cleanfile\n",
    "        cleanfile=f\"{cleanresults}/{year}_{month}.csv\"\n",
    "\n",
    "        #output_path\n",
    "        output_path=Path(rawfile)\n",
    "\n",
    "        #if\n",
    "        if output_path.is_file():\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{cleanfile}\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=10,\n",
    "                #encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                )\n",
    "\n",
    "            #print\n",
    "            print(f\"{i}/{tot} - {filestem} - already done\") \n",
    "\n",
    "        #elif\n",
    "        elif not output_path.is_file():\n",
    "\n",
    "            #ZipFile\n",
    "            with ZipFile(zipfile, \"r\") as zip_ref:\n",
    "\n",
    "                #namelist\n",
    "                namelist=zip_ref.namelist()\n",
    "\n",
    "                #tempfile\n",
    "                tempfile=[x for x in namelist if x.endswith(\".csv\")][0]\n",
    "                \n",
    "                #extract\n",
    "                zip_ref.extract(tempfile, zipresults)\n",
    "            \n",
    "            #p\n",
    "            p=Path(f\"{zipresults}/{tempfile}\")\n",
    "\n",
    "            #rename\n",
    "            p.rename(rawfile)\n",
    "\n",
    "            #firstcol\n",
    "            firstcol=\"HCPCS Code\"\n",
    "\n",
    "            #reader\n",
    "            with open(rawfile, newline='') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                \n",
    "                #for\n",
    "                for j, row in enumerate(reader):\n",
    "                    \n",
    "                    #if\n",
    "                    if firstcol in row:\n",
    "                        \n",
    "                        #header\n",
    "                        header=j\n",
    "\n",
    "                        #break\n",
    "                        break\n",
    "\n",
    "            #read_csv\n",
    "            filepath=f\"{rawfile}\"\n",
    "            sep=\",\"\n",
    "            df_i=pd.read_csv(\n",
    "                filepath, \n",
    "                sep=sep,\n",
    "                header=header,\n",
    "                usecols=usecols,\n",
    "                dtype=\"string\",\n",
    "                #nrows=10,\n",
    "                encoding=\"latin-1\",\n",
    "                #on_bad_lines=\"skip\",\n",
    "                ) \n",
    "            \n",
    "            #lowercase\n",
    "            df_i=_lowercase(df_i)\n",
    "\n",
    "            #dropna\n",
    "            df_i=df_i.dropna(subset=dropna_cols)\n",
    "\n",
    "            #dropobs\n",
    "\n",
    "            #year\n",
    "            df_i[\"year\"]=year\n",
    "\n",
    "            #month\n",
    "            df_i[\"month\"]=month\n",
    "\n",
    "            #todatetime\n",
    "            todatetime_cols=[\n",
    "                \"month\",\n",
    "                ]\n",
    "            errors=\"raise\"\n",
    "            format=\"%m\"\n",
    "            df_i=_todatetime(df_i, todatetime_cols, errors, format)\n",
    "            #quarter\n",
    "            df_i[\"quarter\"]=pd.DatetimeIndex(df_i[\"month\"], ambiguous=\"NaT\").quarter\n",
    "\n",
    "            #sortvalues            \n",
    "            df_i=df_i.sort_values(\n",
    "                by=sortvalues_cols,\n",
    "                )\n",
    "\n",
    "            #ordered\n",
    "            df_i=df_i[ordered_cols]\n",
    "\n",
    "            #to_csv\n",
    "            filepath=f\"{cleanfile}\"\n",
    "            df_i.to_csv(filepath, index=False)\n",
    "\n",
    "            #print\n",
    "            print(f\"{i}/{tot} - {filestem} - done\")  \n",
    "\n",
    "        #frames\n",
    "        frames[i]=df_i\n",
    "\n",
    "    #concat\n",
    "    left=pd.concat(frames)\n",
    "\n",
    "    #right\n",
    "    filepath=\"ciani/_medicarepartbspending/medicarepartbspending.csv\"\n",
    "    sep=\",\"\n",
    "    usecols=[\"HCPCS_Cd\", \"Brnd_Name\", \"Gnrc_Name\"]\n",
    "    right=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=10,\n",
    "        #encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        ) \n",
    "    right=right.drop_duplicates(subset=[\"HCPCS_Cd\"])\n",
    "\n",
    "    #merge\n",
    "    how=\"left\"\n",
    "    left_on=[\"HCPCS Code\"]\n",
    "    right_on=[\"HCPCS_Cd\"]\n",
    "    suffixes=(\"_left\", \"_right\")\n",
    "    indicator=f\"_merge_{result}\"\n",
    "    validate=\"m:1\"\n",
    "    df=pd.merge(\n",
    "        left=left,\n",
    "        right=right,\n",
    "        how=how,\n",
    "        left_on=left_on,\n",
    "        right_on=right_on,\n",
    "        suffixes=suffixes,\n",
    "        indicator=indicator,\n",
    "        validate=validate,\n",
    "        )\n",
    "\n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"HCPCS Code\",\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        ]          \n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "    \n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"HCPCS Code\",\n",
    "        \"HCPCS Code Dosage\",\n",
    "        \"Payment Limit\",\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        \"Brnd_Name\",\n",
    "        \"Gnrc_Name\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_medicarepartbasp(folders, items)\n",
    "\n",
    "\n",
    "#_medicaidnadac\n",
    "#https://data.medicaid.gov/nadac\n",
    "folders=[\"ciani/data/medicaidnadac\", \"ciani/_medicaidnadac\"]\n",
    "items=[\"medicaidnadac\"]\n",
    "def _medicaidnadac(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    #resource=items[0]\n",
    "    result=items[0]\n",
    "\n",
    "    #rawresults\n",
    "    rawresults=f\"{results}/raw\"\n",
    "\n",
    "    #_folder_to_filestems\n",
    "    files, filestems = _folder_to_filestems(resources)\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(filestems)\n",
    "\n",
    "    #tot\n",
    "    tot=nobs-1\n",
    "\n",
    "    #ordered\n",
    "    frames=[None]*nobs\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"ndc_description\",\n",
    "        \"ndc\",\n",
    "        \"nadac_per_unit\",\n",
    "        ]\n",
    "    \n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"ndc_description\",\n",
    "        \"ndc\",\n",
    "        \"nadac_per_unit\",\n",
    "        ]\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"ndc_description\",\n",
    "        \"ndc\",\n",
    "        ]\n",
    "    \n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"ndc_description\",\n",
    "        \"ndc\",\n",
    "        \"nadac_per_unit\",\n",
    "        \"year\",\n",
    "        ]\n",
    "\n",
    "    #for\n",
    "    for i, filestem in enumerate(filestems):\n",
    "\n",
    "        #year\n",
    "        year=f\"{filestem}\"\n",
    "\n",
    "        #rawfile\n",
    "        rawfile=f\"{rawresults}/{filestem}.csv\"\n",
    "\n",
    "        #filepath\n",
    "        filepath=f\"{resources}/{filestem}.csv\"\n",
    "\n",
    "        #read_csv\n",
    "        sep=\",\"\n",
    "        df_i=pd.read_csv(\n",
    "            filepath, \n",
    "            sep=sep,\n",
    "            usecols=usecols,\n",
    "            dtype=\"string\",\n",
    "            #nrows=10,\n",
    "            #encoding=\"latin-1\",\n",
    "            #on_bad_lines=\"skip\",\n",
    "            ) \n",
    "            \n",
    "        #lowercase\n",
    "        df_i=_lowercase(df_i)\n",
    "\n",
    "        #dropna\n",
    "        df_i=df_i.dropna(subset=dropna_cols)\n",
    "\n",
    "        #dropobs\n",
    "\n",
    "        #year\n",
    "        df_i[\"year\"]=year\n",
    "\n",
    "        #tonumeric\n",
    "        tonumeric_cols=[\n",
    "            \"nadac_per_unit\",\n",
    "            ]\n",
    "        errors=\"raise\"\n",
    "        df_i=_tonumeric(df_i, tonumeric_cols, errors)\n",
    "\n",
    "        #_groupby\n",
    "        by=[\n",
    "            \"ndc_description\",\n",
    "            \"year\",\n",
    "            ]\n",
    "        dict_agg_colfunctions={\n",
    "            \"ndc\": _firstvalue_join_notna,\n",
    "            \"nadac_per_unit\": [\"mean\"],\n",
    "            }\n",
    "        df_i=_groupby(df_i, by, dict_agg_colfunctions)\n",
    "\n",
    "        #sortvalues            \n",
    "        df_i=df_i.sort_values(\n",
    "            by=sortvalues_cols,\n",
    "            )\n",
    "\n",
    "        #ordered\n",
    "        df_i=df_i[ordered_cols]\n",
    "\n",
    "        #to_csv\n",
    "        filepath=f\"{rawfile}\"\n",
    "        df_i.to_csv(filepath, index=False)\n",
    "\n",
    "        #frames\n",
    "        frames[i]=df_i\n",
    "\n",
    "        #print\n",
    "        print(f\"{i}/{tot} - {filestem} - done\")  \n",
    "\n",
    "    #concat\n",
    "    df=pd.concat(frames)\n",
    "\n",
    "    #sortvalues\n",
    "    \n",
    "    #ordered\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_medicaidnadac(folders, items)\n",
    "\n",
    "\n",
    "#_fdaorangeproducts\n",
    "#https://www.fda.gov/drugs/drug-approvals-and-databases/orange-book-data-files\n",
    "folders=[\"ciani/data/fdaorange\", \"ciani/_fdaorange\"]\n",
    "items=[\"products\", \"products\"]\n",
    "def _fdaorangeproducts(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"Ingredient\",\n",
    "        \"DF;Route\",\n",
    "        \"Trade_Name\",\n",
    "        \"Applicant\",\n",
    "        \"Strength\",\n",
    "        \"Appl_Type\",\n",
    "        \"Appl_No\",\n",
    "        \"Product_No\",\n",
    "        \"TE_Code\",\n",
    "        \"Approval_Date\",\n",
    "        \"Type\",\n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.txt\"\n",
    "    sep=\"~\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=10,\n",
    "        #encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        )\n",
    "    \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"Trade_Name\",\n",
    "        \"Approval_Date\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"Approval_Date\"]!=\"approved prior to jan 1, 1982\"]\n",
    "\n",
    "    #dosageform route\n",
    "    df[[\"dosageform\", \"route\"]] = df[\"DF;Route\"].str.split(';', expand=True)\n",
    "\n",
    "    #strength\n",
    "    pattern=r\"\\s*\\([^)]*\\)\"\n",
    "    df[\"strength\"]=df[\"Strength\"].str.replace(pattern, \"\", regex=True)\n",
    "\n",
    "    #todate\n",
    "    todatetime_cols=[\n",
    "        \"Approval_Date\",\n",
    "        ]\n",
    "    errors=\"raise\"\n",
    "    format=\"%b %d, %Y\"\n",
    "    df=_todatetime(df, todatetime_cols, errors, format)\n",
    "    #year\n",
    "    df[\"approval_year\"]=pd.DatetimeIndex(df[\"Approval_Date\"], ambiguous=\"NaT\").year\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"approval_year\"]>=2006]\n",
    "    df=df[df[\"approval_year\"]<=2021]\n",
    "\n",
    "    #dropdups\n",
    "    dropdups_cols=[\n",
    "        \"Trade_Name\",\n",
    "        \"Applicant\",\n",
    "        \"Appl_No\",\n",
    "        \"strength\",\n",
    "        \"approval_year\",\n",
    "        ]\n",
    "    #df=df.drop_duplicates(subset=dropdups_cols)\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"Appl_No\",\n",
    "        \"Product_No\",\n",
    "        ]\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"Ingredient\",\n",
    "        \"dosageform\",\n",
    "        \"route\",\n",
    "        \"Trade_Name\",\n",
    "        \"Applicant\",\n",
    "        \"Appl_Type\",\n",
    "        \"Appl_No\",\n",
    "        \"Product_No\",\n",
    "        \"TE_Code\",\n",
    "        \"Approval_Date\",\n",
    "        \"Type\",\n",
    "        \"strength\",\n",
    "        \"approval_year\"\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_fdaorangeproducts(folders, items)\n",
    "\n",
    "\n",
    "#_name_suffixs\n",
    "def _name_suffixs(names, suffixes):\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(names)\n",
    "\n",
    "    #name_suffixs\n",
    "    name_suffixs=[None]*nobs\n",
    "\n",
    "    #for\n",
    "    for i, name in enumerate(names):\n",
    "\n",
    "        #if\n",
    "        if pd.isna(name):\n",
    "\n",
    "            #name_suffix\n",
    "            name_suffix=None\n",
    "\n",
    "        #elif\n",
    "        elif not pd.isna(name):\n",
    "\n",
    "            #suffix\n",
    "            suffix=suffixes[i]\n",
    "\n",
    "            #if\n",
    "            if pd.isna(suffix):\n",
    "\n",
    "                #name_suffix\n",
    "                name_suffix=f\"{name}\"\n",
    "\n",
    "            #elif\n",
    "            elif not pd.isna(suffix):\n",
    "\n",
    "                #name_suffix\n",
    "                name_suffix=f\"{name} {suffix}\"\n",
    "\n",
    "        #name_suffixs\n",
    "        name_suffixs[i]=name_suffix\n",
    "\n",
    "    #return\n",
    "    return name_suffixs\n",
    "\n",
    "\n",
    "#_num_dems\n",
    "def _num_dems(numerators, denominators):\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(numerators)\n",
    "\n",
    "    #strengths\n",
    "    strengths=[None]*nobs\n",
    "\n",
    "    #for\n",
    "    for i, numerator in enumerate(numerators):\n",
    "\n",
    "        #denominator\n",
    "        denominator=denominators[i]\n",
    "\n",
    "        #if\n",
    "        if pd.isna(numerator) or pd.isna(denominator):\n",
    "\n",
    "            #strength\n",
    "            strength=None\n",
    "\n",
    "        #elif\n",
    "        elif pd.notna(numerator) and pd.notna(denominator):\n",
    "\n",
    "            #split\n",
    "            numerator_list = numerator.split('; ')\n",
    "            denominator_list = denominator.split('; ')\n",
    "\n",
    "            #zip\n",
    "            strength_list = [f\"{x}/{y}\" for x, y in zip(numerator_list, denominator_list)]\n",
    "\n",
    "            #strength\n",
    "            strength = '; '.join(strength_list)\n",
    "\n",
    "        #strengths\n",
    "        strengths[i]=strength\n",
    "\n",
    "    #return\n",
    "    return strengths\n",
    "\n",
    "\n",
    "#_fdandcproduct\n",
    "#https://www.fda.gov/drugs/drug-approvals-and-databases/national-drug-code-directory\n",
    "#https://www.fda.gov/drugs/drug-approvals-and-databases/ndc-product-file-definitions\n",
    "folders=[\"ciani/data/fdandc\", \"ciani/_fdandc\"]\n",
    "items=[\"product\", \"product\"]\n",
    "def _fdandcproduct(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"PRODUCTID\",\n",
    "        \"PRODUCTTYPENAME\",\n",
    "        \"PROPRIETARYNAME\",\n",
    "        \"PROPRIETARYNAMESUFFIX\",\n",
    "        \"NONPROPRIETARYNAME\",\n",
    "        \"DOSAGEFORMNAME\",\n",
    "        \"ROUTENAME\",\n",
    "        \"STARTMARKETINGDATE\",\n",
    "        \"ENDMARKETINGDATE\",\n",
    "        \"MARKETINGCATEGORYNAME\",\n",
    "        \"APPLICATIONNUMBER\",\n",
    "        \"LABELERNAME\",\n",
    "        \"SUBSTANCENAME\",\n",
    "        \"ACTIVE_NUMERATOR_STRENGTH\",\n",
    "        \"ACTIVE_INGRED_UNIT\",\n",
    "        \"PHARM_CLASSES\",\n",
    "        \"NDC_EXCLUDE_FLAG\",\n",
    "    \n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.txt\"\n",
    "    sep=\"\\t\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=10,\n",
    "        encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        )\n",
    "    \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"APPLICATIONNUMBER\",\n",
    "        \"STARTMARKETINGDATE\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #dropobs\n",
    "    dropobs=[\n",
    "        \"nda\",\n",
    "        \"anda\",\n",
    "        \"nda authorized generic\",\n",
    "        ]\n",
    "    df=df[df[\"MARKETINGCATEGORYNAME\"].isin(dropobs)]\n",
    "    dropobs=[\n",
    "        \"e\",\n",
    "        \"u\",\n",
    "        \"i\",\n",
    "        ]\n",
    "    df=df[~df[\"NDC_EXCLUDE_FLAG\"].isin(dropobs)]\n",
    "\n",
    "    #name\n",
    "    names=df[\"PROPRIETARYNAME\"].tolist()\n",
    "    suffixes=df[\"PROPRIETARYNAMESUFFIX\"].tolist()\n",
    "    name_suffixs=_name_suffixs(names, suffixes)\n",
    "    df[\"name\"]=name_suffixs\n",
    "\n",
    "    #applno\n",
    "    df[\"applno\"]=df[\"APPLICATIONNUMBER\"].str[-6:]\n",
    "\n",
    "    #strength\n",
    "    numerators=df[\"ACTIVE_NUMERATOR_STRENGTH\"].tolist()\n",
    "    denominators=df[\"ACTIVE_INGRED_UNIT\"].tolist()\n",
    "    strengths=_num_dems(numerators, denominators)\n",
    "    df[\"strength\"]=strengths\n",
    "\n",
    "    #todate\n",
    "    todatetime_cols=[\n",
    "        \"STARTMARKETINGDATE\",\n",
    "        ]\n",
    "    errors=\"raise\"\n",
    "    format=\"%Y%m%d\"\n",
    "    df=_todatetime(df, todatetime_cols, errors, format)\n",
    "    #year\n",
    "    df[\"startmarketing_year\"]=pd.DatetimeIndex(df[\"STARTMARKETINGDATE\"], ambiguous=\"NaT\").year\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"startmarketing_year\"]>=2006]\n",
    "    df=df[df[\"startmarketing_year\"]<=2021]\n",
    "\n",
    "    #dropdups\n",
    "    dropdups_cols=[\n",
    "        \"LABELERNAME\",\n",
    "        \"name\",\n",
    "        \"applno\",\n",
    "        \"strength\",\n",
    "        \"startmarketing_year\",\n",
    "        ]\n",
    "    #df=df.drop_duplicates(subset=dropdups_cols)\n",
    "\n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"applno\",\n",
    "        \"PRODUCTID\",\n",
    "        ]\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"PRODUCTID\",\n",
    "        \"PRODUCTTYPENAME\",\n",
    "        \"NONPROPRIETARYNAME\",\n",
    "        \"DOSAGEFORMNAME\",\n",
    "        \"ROUTENAME\",\n",
    "        \"STARTMARKETINGDATE\",\n",
    "        \"ENDMARKETINGDATE\",\n",
    "        \"MARKETINGCATEGORYNAME\",\n",
    "        \"APPLICATIONNUMBER\",\n",
    "        \"LABELERNAME\",\n",
    "        \"SUBSTANCENAME\",\n",
    "        \"PHARM_CLASSES\",\n",
    "        \"name\",\n",
    "        \"applno\",\n",
    "        \"strength\",\n",
    "        \"startmarketing_year\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "\n",
    "\n",
    "#_brands_generics\n",
    "def _brands_generics(products):\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(products)\n",
    "\n",
    "    #brands\n",
    "    brands=[None]*nobs\n",
    "\n",
    "    #generics\n",
    "    generics=[None]*nobs\n",
    "\n",
    "    #comma\n",
    "    comma=\",\"\n",
    "\n",
    "    #leftparen\n",
    "    leftparen=\"(\"\n",
    "\n",
    "    for i, product in enumerate(products):\n",
    "\n",
    "        #replace\n",
    "        product=product.replace(\";\", \",\")\n",
    "        product=product.replace(\"[\", \"(\").replace(\"]\", \")\")\n",
    "\n",
    "        #if\n",
    "        if comma not in product:\n",
    "\n",
    "            #if\n",
    "            if not leftparen in product:\n",
    "\n",
    "                #brand\n",
    "                brand=product.strip()\n",
    "\n",
    "                #generic\n",
    "                generic=None\n",
    "\n",
    "            #elif\n",
    "            elif leftparen in product:\n",
    "\n",
    "                #replace\n",
    "                product=product.replace(\",\", \"\")\n",
    "                product=product.replace(\" and \", \" \")\n",
    "\n",
    "                #match\n",
    "                pattern=r\"(.+?)\\s*\\((.+?)\\)\"\n",
    "                match=re.match(pattern, product)\n",
    "\n",
    "                #brand\n",
    "                brand=match.group(1).strip()\n",
    "\n",
    "                #generic\n",
    "                generic=match.group(2).strip()\n",
    "\n",
    "        #elif\n",
    "        elif comma in product:\n",
    "\n",
    "            #comma_idx\n",
    "            comma_idx = product.find(comma)\n",
    "\n",
    "            #if\n",
    "            if leftparen not in product: \n",
    "\n",
    "                #brand\n",
    "                brand=product.split(comma)[0].strip()\n",
    "\n",
    "                #generic\n",
    "                generic=product.split(comma)[1].strip()\n",
    "\n",
    "            #elif\n",
    "            elif leftparen in product:\n",
    "\n",
    "                #leftparen_idx\n",
    "                leftparen_idx = product.find(leftparen)\n",
    "\n",
    "                #if\n",
    "                if comma_idx<leftparen_idx:\n",
    "\n",
    "                    #sub\n",
    "                    pattern=r\"\\s*\\([^)]*\\)\"\n",
    "                    product=re.sub(pattern, \"\", product)\n",
    "\n",
    "                    #brand\n",
    "                    brand=product.split(comma)[0].strip()\n",
    "\n",
    "                    #generic\n",
    "                    generic=product.split(comma)[1].strip()\n",
    "            \n",
    "                #elif\n",
    "                elif comma_idx>leftparen_idx:\n",
    "\n",
    "                    #replace\n",
    "                    product=product.replace(\",\", \"\")\n",
    "                    product=product.replace(\" and \", \" \")\n",
    "\n",
    "                    #match\n",
    "                    pattern=r\"(.+?)\\s*\\((.+?)\\)\"\n",
    "                    match=re.match(pattern, product)\n",
    "\n",
    "                    #brand\n",
    "                    brand=match.group(1).strip()\n",
    "\n",
    "                    #generic\n",
    "                    generic=match.group(2).strip()\n",
    "\n",
    "        #brands\n",
    "        brands[i]=brand\n",
    "\n",
    "        #generics\n",
    "        generics[i]=generic\n",
    "\n",
    "    #return\n",
    "    return brands, generics\n",
    "\n",
    "\n",
    "#_fdaaalist\n",
    "#https://www.fda.gov/drugs/nda-and-bla-approvals/accelerated-approvals\n",
    "#https://www.fda.gov/drugs/postmarket-requirements-and-commitments/postmarketing-requirements-and-commitments-downloadable-database-file\n",
    "folders=[\"ciani/data/fdaaa\", \"ciani/_fdaaa\"]\n",
    "items=[\"Final CDER AA Approvals as of 12-31-23_1\", \"list\"]\n",
    "def _fdaaalist(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"Application Number\",\n",
    "        \"Proprietary  Name\",\n",
    "        \"Established  Name\",\n",
    "        \"Applicant\",\n",
    "        \"FDA Received Date\",\n",
    "        \"Accelerated Approval Date\",\n",
    "        \"Accelerated Approval Indication\",\n",
    "        \"Conversion-Withdrawal Status\",\n",
    "        \"Full Approval Conversion- Withdrawal Date\",\n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.csv\"\n",
    "    sep=\",\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=100,\n",
    "        #encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        )\n",
    "\n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"Application Number\",   \n",
    "        \"Accelerated Approval Date\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #replace\n",
    "    df[\"Application Number\"]=df[\"Application Number\"].str.replace(\"\\n\", \"\")\n",
    "\n",
    "    #nda_bla\n",
    "    df[\"nda_bla\"]=df[\"Application Number\"].str[0:3]\n",
    "\n",
    "    #applno\n",
    "    df[\"applno\"]=df[\"Application Number\"].str[4:(4+6)]\n",
    "\n",
    "    #supplement\n",
    "    df[\"supplement\"]=df[\"Application Number\"].str[(4+6):]\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"nda_bla\"]==\"nda\"]\n",
    "    \n",
    "    #converted\n",
    "    df[\"converted\"]=np.where(df[\"Conversion-Withdrawal Status\"]==\"converted\", 1, 0)\n",
    "\n",
    "    #withdrawn\n",
    "    df[\"withdrawn\"]=np.where(df[\"Conversion-Withdrawal Status\"].str.contains(\"withdrawn\"), 1, 0)\n",
    "\n",
    "    #converted_date\n",
    "    df[\"converted_date\"]=np.where(df[\"converted\"]==1, df[\"Full Approval Conversion- Withdrawal Date\"], None)\n",
    "\n",
    "    #withdrawn_date\n",
    "    df[\"withdrawn_date\"]=np.where(df[\"withdrawn\"]==1, df[\"Full Approval Conversion- Withdrawal Date\"], None)\n",
    "\n",
    "    #todate\n",
    "    todatetime_cols=[\n",
    "        \"Accelerated Approval Date\",\n",
    "        ]\n",
    "    errors=\"raise\"\n",
    "    format=\"%d/%m/%Y\"\n",
    "    df=_todatetime(df, todatetime_cols, errors, format)\n",
    "    #year\n",
    "    df[\"approval_year\"]=pd.DatetimeIndex(df[\"Accelerated Approval Date\"], ambiguous=\"NaT\").year\n",
    "    df[\"converted_year\"]=pd.DatetimeIndex(df[\"converted_date\"], ambiguous=\"NaT\").year\n",
    "    df[\"withdrawn_year\"]=pd.DatetimeIndex(df[\"withdrawn_date\"], ambiguous=\"NaT\").year\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"approval_year\"]>=2006]\n",
    "    df=df[df[\"approval_year\"]<=2021]\n",
    "\n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"applno\",\n",
    "        \"approval_year\",\n",
    "        ]\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "\n",
    "    #dropdups\n",
    "    dropdups_cols=[\n",
    "        \"applno\",\n",
    "        ]\n",
    "    df=df.drop_duplicates(subset=dropdups_cols)\n",
    "    \n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"applno\",\n",
    "        ]\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"Proprietary  Name\",\n",
    "        \"Established  Name\",\n",
    "        \"Applicant\",\n",
    "        \"FDA Received Date\",\n",
    "        \"Accelerated Approval Date\",\n",
    "        \"Accelerated Approval Indication\",\n",
    "        \"applno\",\n",
    "        \"supplement\",\n",
    "        \"converted_date\",\n",
    "        \"withdrawn_date\",\n",
    "        \"approval_year\",\n",
    "        \"converted_year\",\n",
    "        \"withdrawn_year\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "\n",
    "\n",
    "#_fdaaapmc\n",
    "#https://www.fda.gov/drugs/nda-and-bla-approvals/accelerated-approvals\n",
    "#https://www.fda.gov/drugs/postmarket-requirements-and-commitments/postmarketing-requirements-and-commitments-downloadable-database-file\n",
    "folders=[\"ciani/data/fdaaa\", \"ciani/_fdaaa\"]\n",
    "items=[\"pmc_commitments\", \"pmc\"]\n",
    "def _fdaaapmc(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"CMT_DESC\",\n",
    "        \"CMT_STATUS\",\n",
    "        \"CMT_STATUS_DESC\",\n",
    "        \"NDA_BLA_APPROVAL_DATE\",\n",
    "        \"NDA_NUMBER\",\n",
    "        \"APPLICANT\",\n",
    "        \"PRODUCT\",\n",
    "        \"CDER_OR_CBER\",\n",
    "        \"SUBPART_FLAG\",\n",
    "        ]\n",
    "    \n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.txt\"\n",
    "    sep=\"~\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=100,\n",
    "        encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        )\n",
    "    \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"NDA_BLA_APPROVAL_DATE\",\n",
    "        \"NDA_NUMBER\",\n",
    "        \"PRODUCT\",\n",
    "        \"SUBPART_FLAG\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"SUBPART_FLAG\"]==\"h\"]\n",
    "\n",
    "    #replace_dict\n",
    "    replace_dict={\n",
    "        \"p\": \"pending\",\n",
    "        \"o\": \"ongoing\",\n",
    "        \"d\": \"delayed\",\n",
    "        \"t\": \"terminated\",\n",
    "        \"s\": \"submitted\",\n",
    "        \"f\": \"fulfilled\",\n",
    "        \"r\": \"released\"\n",
    "        }\n",
    "    df[\"cmt_status_explanation\"]=df[\"CMT_STATUS\"].replace(replace_dict)\n",
    "\n",
    "    #_groupby\n",
    "    by=[\n",
    "        \"NDA_NUMBER\",\n",
    "        ]\n",
    "    dict_agg_colfunctions={\n",
    "        \"CMT_DESC\": _firstvalue_join_notna,\n",
    "        \"CMT_STATUS\": _firstvalue_join_notna,\n",
    "        \"CMT_STATUS_DESC\": _firstvalue_join_notna,\n",
    "        \"NDA_BLA_APPROVAL_DATE\": _firstvalue_join_notna,\n",
    "        \"APPLICANT\": _firstvalue_join_notna,\n",
    "        \"PRODUCT\": _firstvalue_join_notna,\n",
    "        \"CDER_OR_CBER\": _firstvalue_join_notna,\n",
    "        \"cmt_status_explanation\": _firstvalue_join_notna,\n",
    "        }\n",
    "    df=_groupby(df, by, dict_agg_colfunctions)\n",
    "\n",
    "    #tolist\n",
    "    products=df[\"PRODUCT\"].tolist()\n",
    "\n",
    "    #brands_generics\n",
    "    brands, generics = _brands_generics(products)\n",
    "\n",
    "    #brand\n",
    "    df[\"brand\"]=brands\n",
    "\n",
    "    #generic\n",
    "    df[\"generic\"]=generics\n",
    "\n",
    "    #todate\n",
    "    todatetime_cols=[\n",
    "        \"NDA_BLA_APPROVAL_DATE\",\n",
    "        ]\n",
    "    errors=\"raise\"\n",
    "    format=\"%m/%d/%Y %H:%M:%S\"\n",
    "    df=_todatetime(df, todatetime_cols, errors, format)\n",
    "    #year\n",
    "    df[\"approval_year\"]=pd.DatetimeIndex(df[\"NDA_BLA_APPROVAL_DATE\"], ambiguous=\"NaT\").year\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"approval_year\"]>=2006]\n",
    "    df=df[df[\"approval_year\"]<=2021]\n",
    "\n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"NDA_NUMBER\",\n",
    "        ]\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"CMT_DESC\",\n",
    "        \"CMT_STATUS\",\n",
    "        \"CMT_STATUS_DESC\",\n",
    "        \"NDA_BLA_APPROVAL_DATE\",\n",
    "        \"NDA_NUMBER\",\n",
    "        \"APPLICANT\",\n",
    "        \"CDER_OR_CBER\",\n",
    "        \"cmt_status_explanation\",\n",
    "        \"brand\",\n",
    "        \"generic\",\n",
    "        \"approval_year\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_fdaaapmc(folders, items)\n",
    "\n",
    "\n",
    "#_applnos\n",
    "def _applnos(values):\n",
    "\n",
    "    #nobs\n",
    "    nobs=len(values)\n",
    "\n",
    "    #applnos\n",
    "    applnos=[None]*nobs\n",
    "\n",
    "    #for\n",
    "    for i, value in enumerate(values):\n",
    "\n",
    "        #if\n",
    "        if pd.isna(value):\n",
    "\n",
    "            #applno\n",
    "            applno=None\n",
    "\n",
    "        #elif\n",
    "        elif not pd.isna(value):\n",
    "\n",
    "            #len\n",
    "            len_value=len(value)\n",
    "\n",
    "            #if\n",
    "            if len_value==6:\n",
    "\n",
    "                #applno\n",
    "                applno=f\"{value}\"\n",
    "\n",
    "            #elif\n",
    "            elif len_value==5:\n",
    "\n",
    "                #applno\n",
    "                applno=f\"0{value}\"\n",
    "\n",
    "        #applnos\n",
    "        applnos[i]=applno\n",
    "\n",
    "    #return\n",
    "    return applnos\n",
    "\n",
    "\n",
    "#_fdanmeapproval\n",
    "#https://www.fda.gov/drugs/drug-approvals-and-databases/compilation-cder-new-molecular-entity-nme-drug-and-new-biologic-approvals\n",
    "folders=[\"ciani/data/fdanmeapproval\", \"ciani/_fdanmeapproval\"]\n",
    "items=[\"Compilation-of-CDER-NME-and-New-Biologic-Approvals-1985-2022\", \"fdanmeapproval\"]\n",
    "def _fdanmeapproval(folders, items):\n",
    "\n",
    "    #folders\n",
    "    resources=folders[0]\n",
    "    results=folders[1]\n",
    "\n",
    "    #items\n",
    "    resource=items[0]\n",
    "    result=items[1]\n",
    "\n",
    "    #usecols\n",
    "    usecols=[\n",
    "        \"Proprietary  Name\",\n",
    "        \"Active Ingredient/Moiety\",\n",
    "        \"Applicant\",\n",
    "        \"NDA/BLA\",\n",
    "        \" Application Number(1)\",\n",
    "        \" Application Number(2)\",\n",
    "        \" Application Number(3)\",\n",
    "        \"Dosage Form(1)\",\n",
    "        \"Route of Administration(1)\",\n",
    "        \"Dosage Form(2)\",\n",
    "        \"Route of Administration(2)\",\n",
    "        \"Dosage Form(3)\",\n",
    "        \"Route of Administration(3)\",\n",
    "        \"FDA Approval Date\",\n",
    "        \"Approval Year\",\n",
    "        \"Abbreviated Indication(s)\",\n",
    "        \"Approved Use(s)\",\n",
    "        \"Review Designation\",\n",
    "        \"Orphan Drug Designation\",\n",
    "        \"Accelerated Approval\",\n",
    "        \"Breakthrough Therapy Designation\",\n",
    "        \"Fast Track Designation\",\n",
    "        \"Qualified Infectious Disease Product\",\n",
    "        \"Issued a Priority Review Voucher\",\n",
    "        \"Redeemed a Priority Review Voucher\",\n",
    "        ]\n",
    "\n",
    "    #read_csv\n",
    "    filepath=f\"{resources}/{resource}.csv\"\n",
    "    sep=\",\"\n",
    "    df=pd.read_csv(\n",
    "        filepath, \n",
    "        sep=sep,\n",
    "        usecols=usecols,\n",
    "        dtype=\"string\",\n",
    "        #nrows=10,\n",
    "        #encoding=\"latin-1\",\n",
    "        #on_bad_lines=\"skip\",\n",
    "        )\n",
    "    \n",
    "    #lowercase\n",
    "    df=_lowercase(df)\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \" Application Number(1)\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #todate\n",
    "    todatetime_cols=[\n",
    "        \"FDA Approval Date\",\n",
    "        ]\n",
    "    errors=\"raise\"\n",
    "    format=\"%m/%d/%Y\"\n",
    "    df=_todatetime(df, todatetime_cols, errors, format)\n",
    "    #year\n",
    "    df[\"approval_year\"]=pd.DatetimeIndex(df[\"FDA Approval Date\"], ambiguous=\"NaT\").year\n",
    "\n",
    "    #dropobs\n",
    "    df=df[df[\"NDA/BLA\"]==\"nda\"]\n",
    "    df=df[df[\"approval_year\"]>=2006]\n",
    "    df=df[df[\"approval_year\"]<=2021]\n",
    "    df=df[df[\"Accelerated Approval\"]!=\"no\"]\n",
    "\n",
    "    #applnos\n",
    "    values=df[\" Application Number(1)\"].tolist()\n",
    "    applnos=_applnos(values)\n",
    "    df[\"applno_1\"]=applnos\n",
    "    values=df[\" Application Number(2)\"].tolist()\n",
    "    applnos=_applnos(values)\n",
    "    df[\"applno_2\"]=applnos\n",
    "    values=df[\" Application Number(3)\"].tolist()\n",
    "    applnos=_applnos(values)\n",
    "    df[\"applno_3\"]=applnos\n",
    "\n",
    "    #rename\n",
    "    rename_dict={\n",
    "        \"Dosage Form(1)\": \"dosage_1\",\n",
    "        \"Dosage Form(2)\": \"dosage_2\",\n",
    "        \"Dosage Form(3)\": \"dosage_3\",\n",
    "        \"Route of Administration(1)\": \"route_1\",\n",
    "        \"Route of Administration(2)\": \"route_2\",\n",
    "        \"Route of Administration(3)\": \"route_3\",\n",
    "        }\n",
    "    df=df.rename(columns=rename_dict)\n",
    "\n",
    "    #wide_to_long\n",
    "    stubnames=[\n",
    "        \"applno\",\n",
    "        \"dosage\",\n",
    "        \"route\",\n",
    "        ]\n",
    "    i=[\n",
    "        \"Proprietary  Name\",\n",
    "        \"Active Ingredient/Moiety\",\n",
    "        \"Applicant\",\n",
    "        \"FDA Approval Date\",\n",
    "        \"Abbreviated Indication(s)\",\n",
    "        \"Approved Use(s)\",\n",
    "        \"Review Designation\",\n",
    "        \"Orphan Drug Designation\",\n",
    "        \"Accelerated Approval\",\n",
    "        \"Breakthrough Therapy Designation\",\n",
    "        \"Fast Track Designation\",\n",
    "        \"Qualified Infectious Disease Product\",\n",
    "        \"Issued a Priority Review Voucher\",\n",
    "        \"Redeemed a Priority Review Voucher\",\n",
    "        \"approval_year\",\n",
    "        ]\n",
    "    j=\"instance\"\n",
    "    sep=\"_\"\n",
    "    suffix=r\"\\w+\"\n",
    "    df=pd.wide_to_long(\n",
    "        df,\n",
    "        stubnames=stubnames,\n",
    "        i=i,\n",
    "        j=j,\n",
    "        sep=sep,\n",
    "        suffix=suffix,\n",
    "        )\n",
    "    df=df.reset_index()\n",
    "\n",
    "    #dropna\n",
    "    dropna_cols=[\n",
    "        \"applno\",\n",
    "        ]\n",
    "    df=df.dropna(subset=dropna_cols)\n",
    "\n",
    "    #sortvalues\n",
    "    sortvalues_cols=[\n",
    "        \"applno\",\n",
    "        ]\n",
    "    df=df.sort_values(\n",
    "        by=sortvalues_cols,\n",
    "        )\n",
    "\n",
    "    #ordered\n",
    "    ordered_cols=[\n",
    "        \"Proprietary  Name\",\n",
    "        \"Active Ingredient/Moiety\",\n",
    "        \"Applicant\",\n",
    "        \"FDA Approval Date\",\n",
    "        \"Abbreviated Indication(s)\",\n",
    "        \"Approved Use(s)\",\n",
    "        \"Review Designation\",\n",
    "        \"Orphan Drug Designation\",\n",
    "        \"Accelerated Approval\",\n",
    "        \"Breakthrough Therapy Designation\",\n",
    "        \"Fast Track Designation\",\n",
    "        \"Qualified Infectious Disease Product\",\n",
    "        \"Issued a Priority Review Voucher\",\n",
    "        \"Redeemed a Priority Review Voucher\",\n",
    "        \"approval_year\",\n",
    "        \"applno\",\n",
    "        \"dosage\",\n",
    "        \"route\",\n",
    "        ]\n",
    "    df=df[ordered_cols]\n",
    "\n",
    "    #to_csv\n",
    "    filepath=f\"{results}/{result}.csv\"\n",
    "    df.to_csv(filepath, index=False)  \n",
    "    #'''\n",
    "#_fdanmeapproval(folders, items)\n",
    "\n",
    "\n",
    "#_medicarepartdspending\n",
    "folders=[\"ciani/data/medicarepartdspending\", \"ciani/_medicarepartdspending\"]\n",
    "items=[\"DSD_PTD_R22_P04_V22_D21_BGM\", \"medicarepartdspending\"]\n",
    "#_medicarepartdspending(folders, items)\n",
    "\n",
    "\n",
    "#_medicarepartbspending\n",
    "folders=[\"ciani/data/medicarepartbspending\", \"ciani/_medicarepartbspending\"]\n",
    "items=[\"DSD_PTB_R22_P07_V10_DYT21_HCPCS\", \"medicarepartbspending\"]\n",
    "#_medicarepartbspending(folders, items)\n",
    "\n",
    "\n",
    "#_medicarepartbasp\n",
    "folders=[\"ciani/data/medicarepartbasp\", \"ciani/_medicarepartbasp\"]\n",
    "items=[\"medicarepartbasp\"]\n",
    "#_medicarepartbasp(folders, items)\n",
    "\n",
    "\n",
    "#_fdaaalist\n",
    "folders=[\"ciani/data/fdaaa\", \"ciani/_fdaaa\"]\n",
    "items=[\"Final CDER AA Approvals as of 12-31-23_1\", \"list\"]\n",
    "#_fdaaalist(folders, items)\n",
    "\n",
    "\n",
    "#_fdanmeapproval\n",
    "folders=[\"ciani/data/fdanmeapproval\", \"ciani/_fdanmeapproval\"]\n",
    "items=[\"Compilation-of-CDER-NME-and-New-Biologic-Approvals-1985-2022\", \"fdanmeapproval\"]\n",
    "#_fdanmeapproval(folders, items)\n",
    "\n",
    "\n",
    "#fdalist_fdanmeapproval\n",
    "folders=[\"ciani/_merged\"]\n",
    "items=[\"fdalist_fdanmeapproval\"]\n",
    "left_path=\"ciani/_fdaaa/list\"\n",
    "left_ons=[\"applno\"]\n",
    "right_path=\"ciani/_fdanmeapproval/fdanmeapproval\"\n",
    "right_ons=[\"applno\"]\n",
    "how=\"inner\"\n",
    "validate=\"1:1\"\n",
    "#_pd_merge(folders, items, left_path, left_ons, right_path, right_ons, how, validate)\n",
    "\n",
    "\n",
    "#medicarepartbasp_medicarepartbspending\n",
    "folders=[\"ciani/_merged\"]\n",
    "items=[\"medicarepartbasp_medicarepartbspending\"]\n",
    "left_path=\"ciani/_medicarepartbasp/medicarepartbasp\"\n",
    "left_ons=[\"HCPCS Code\", \"Brnd_Name\", \"Gnrc_Name\", \"year\"]\n",
    "right_path=\"ciani/_medicarepartbspending/medicarepartbspending\"\n",
    "right_ons=[\"HCPCS_Cd\", \"Brnd_Name\", \"Gnrc_Name\", \"year\"]\n",
    "how=\"left\"\n",
    "validate=\"m:1\"\n",
    "#_pd_merge(folders, items, left_path, left_ons, right_path, right_ons, how, validate)\n",
    "\n",
    "\n",
    "#medicarepartbasp_medicarepartbspending_fdalist_fdanmeapproval\n",
    "folders=[\"ciani/_merged\"]\n",
    "items=[\"medicarepartbasp_medicarepartbspending_fdalist_fdanmeapproval\"]\n",
    "left_path=\"ciani/_merged/medicarepartbasp_medicarepartbspending\"\n",
    "left_ons=[\"Brnd_Name\"]\n",
    "right_path=\"ciani/_merged/fdalist_fdanmeapproval\"\n",
    "right_ons=[\"Proprietary  Name_left\"]\n",
    "blocking_vars=[]\n",
    "threshold=0.9\n",
    "how=\"inner\"\n",
    "validate=\"m:1\"\n",
    "#_linktransformer(folders, items, left_path, left_ons, right_path, right_ons, blocking_vars, threshold, how, validate)\n",
    "\n",
    "\n",
    "#medicarepartdspending_fdalist_fdanmeapproval\n",
    "folders=[\"ciani/_merged\"]\n",
    "items=[\"medicarepartdspending_fdalist_fdanmeapproval\"]\n",
    "left_path=\"ciani/_medicarepartdspending/medicarepartdspending\"\n",
    "left_ons=[\"Brnd_Name\"]\n",
    "right_path=\"ciani/_merged/fdalist_fdanmeapproval\"\n",
    "right_ons=[\"Proprietary  Name_left\"]\n",
    "blocking_vars=[]\n",
    "threshold=0.9\n",
    "how=\"inner\"\n",
    "validate=\"m:1\"\n",
    "#_linktransformer(folders, items, left_path, left_ons, right_path, right_ons, blocking_vars, threshold, how, validate)\n",
    "\n",
    "\n",
    "#fdalist_fdanmeapproval_cma\n",
    "folders=[\"ciani/_merged\"]\n",
    "items=[\"fdalist_fdanmeapproval_cma\"]\n",
    "left_path=\"ciani/_merged/fdalist_fdanmeapproval\"\n",
    "left_ons=[\"Proprietary  Name_left\"]\n",
    "right_path=\"ciani/data/cma/cma\"\n",
    "right_ons=[\"Commercial name\"]\n",
    "blocking_vars=[]\n",
    "threshold=0.9\n",
    "how=\"inner\"\n",
    "validate=\"1:1\"\n",
    "#_linktransformer(folders, items, left_path, left_ons, right_path, right_ons, blocking_vars, threshold, how, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d1181-fd9a-4d32-89a8-9464101c3895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

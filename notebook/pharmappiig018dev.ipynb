{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a1aac1-95a6-44f0-b2e3-9eee3b8c6731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:94: SyntaxWarning: invalid escape sequence '\\-'\n",
      "<>:246: SyntaxWarning: invalid escape sequence '\\-'\n",
      "<>:94: SyntaxWarning: invalid escape sequence '\\-'\n",
      "<>:246: SyntaxWarning: invalid escape sequence '\\-'\n",
      "C:\\Users\\NCT\\AppData\\Local\\Temp\\ipykernel_16844\\1469282560.py:94: SyntaxWarning: invalid escape sequence '\\-'\n",
      "  num = (re.findall(\"([0-9.\\-]+)\", num))\n",
      "C:\\Users\\NCT\\AppData\\Local\\Temp\\ipykernel_16844\\1469282560.py:246: SyntaxWarning: invalid escape sequence '\\-'\n",
      "  num = (re.findall(\"([0-9.\\-]+)\", num))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "drug name for output file:  praziquantel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find 1 pages of praziquantel on DailyMed\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 326\u001b[0m\n\u001b[0;32m    324\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreindex(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMainDrug\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNDC\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormulation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInactive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrength\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNII\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#for some reason this line removes all inactive except ndcs\u001b[39;00m\n\u001b[0;32m    325\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMainDrug\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMainDrug\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;66;03m#need to make lower case to match that in formulation column\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormulation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFormulation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    327\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [Formulation\u001b[38;5;241m.\u001b[39mreplace(MainDrug, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m Formulation, MainDrug \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormulation\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMainDrug\u001b[39m\u001b[38;5;124m'\u001b[39m])] \u001b[38;5;66;03m#this drop the main drug in formulation\u001b[39;00m\n\u001b[0;32m    328\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormulation\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# wworking parent folder\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# print(\"Start import package\")\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "import requests\n",
    "import re\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "# import ssl\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "# print(\"Import package done!\")\n",
    "\n",
    "## First Part: Enter Drug Name and Use DailyMeds Search Engigne to Bring Up All Pages in a List##\n",
    "\n",
    "name_drug = input(\"drug name for output file: \")\n",
    "drug = name_drug.lower().replace(' ', '+')\n",
    "# print(drug)\n",
    "# create path\n",
    "iig_file = os.path.join('../iigdata', drug + '_inactive_ingredient_list.txt')\n",
    "linklist_file = os.path.join('linklistdata', drug + '_linklist' +'.txt')\n",
    "# drug = input(\"Enter Drug Name:\")\n",
    "# base_url = 'https://dailymed.nlm.nih.gov/dailymed/search.cfm?labeltype=all&query=' + drug\n",
    "base_url = 'https://dailymed.nlm.nih.gov/dailymed/search.cfm?query=' + drug + '&searchdb=all&labeltype=all&sortby=rel&audience=professional&page=1&pagesize=200'\n",
    "r = requests.get(base_url)\n",
    "\n",
    "soup = bsoup(r.text, 'html.parser')\n",
    "#finds all the total pages tags#\n",
    "numpages = soup.find_all('span', re.compile(r\".*total-pages.*\"))\n",
    "\n",
    "# totpage = list()\n",
    "\n",
    "x = list()\n",
    "for num in numpages:\n",
    "    num = str(num)\n",
    "    x = re.findall('>(.*?)<', num)\n",
    "# totalpages = int(x[0])\n",
    "\n",
    "\n",
    "if len(x) == 0:\n",
    "\n",
    "    # Add 1 because Python range.\n",
    "    url_list = 'https://dailymed.nlm.nih.gov/dailymed/search.cfm?labeltype=all&query=' + drug\n",
    "\n",
    "    df_total = pd.DataFrame()\n",
    "\n",
    "    ## Second Part: Take the list of links and get a list of those links#######\n",
    "\n",
    "    # For avoid 403-error using User-Agent\n",
    "    req = urllib.request.Request(url_list, headers={'User-Agent' : \"Magic Browser\"})\n",
    "    response = urllib.request.urlopen( req )\n",
    "    html = response.read()\n",
    "    # Parsing response\n",
    "    soup = bsoup(html, 'html.parser')\n",
    "    wwwlist= list()\n",
    "    tags= soup('a')\n",
    "    for tag in tags:\n",
    "        mlink = tag.get('href')\n",
    "        wwwlist.append(mlink)\n",
    "    resi = list()\n",
    "    for x in wwwlist:\n",
    "        if x == None:\n",
    "            wwwlist.remove(x)\n",
    "            continue\n",
    "    goodlist = list(filter(None, wwwlist)) #this removes Nonetype from the list, this was a problem\n",
    "    subs = 'dailymed/drugInfo.cfm' #gives  variable to what im looking for\n",
    "    resi = [i for i in goodlist if subs in i] #finds all the links\n",
    "    linklist = list()\n",
    "    for long in resi:\n",
    "        long = \"https://dailymed.nlm.nih.gov\" + long #this add to the full website\n",
    "        linklist.append(long)\n",
    "        continue\n",
    "\n",
    "### This takes all the links and adds them to the database####    Note this does not work yet for BRAND and COMBO Drugs\n",
    "\n",
    "    for bbb in linklist:\n",
    "        html = urlopen(bbb).read() #note removed , context=ctx from the urlopen (bbb)\n",
    "        soup = bsoup(html, \"html.parser\")\n",
    "        newlist = list()\n",
    "        tags = soup('td') #this looks through the website and finds tags with \"td\")\n",
    "        for tag in tags:\n",
    "            tag = str(tag)\n",
    "            if tag == \".\":\n",
    "                tags.remove(tag)\n",
    "                continue\n",
    "            ndc = (re.findall(\"NDC:(.*?)</td>\", tag)) #finds all the NDCs\n",
    "            for num in ndc:\n",
    "                num = str(num)\n",
    "                num = (re.findall(\"([0-9.\\-]+)\", num))\n",
    "                for small in num:\n",
    "                    shortndc = small[:+10] #trims the NDCS to first 7 digits\n",
    "                    if shortndc not in newlist:\n",
    "                        newlist.append(shortndc)\n",
    "                        continue\n",
    "            ing = (re.findall(\"<strong>(.*?)</strong>\", tag)) #finds all the ingredients\n",
    "            for lala in ing:\n",
    "            \n",
    "                newlist.append(lala)\n",
    "                continue\n",
    "            form = (re.findall('<span class=\"contentTableReg\">(.*?)/span>', tag)) #finds all the formulations\n",
    "            for newnew in form:\n",
    "                newlist.append(newnew)\n",
    "                continue\n",
    "            strength1 = (re.findall('<td class=\"formItem\">(.*?)</td>', tag)) #this finds all strentghs and below removes fluff\n",
    "            for gggg1 in strength1:\n",
    "                if '(UNII:' in gggg1:\n",
    "                    # if len(re.findall(r'UNII:\\s*([\\w\\d]+)', gggg1))>0:\n",
    "                    inactive = re.findall(r'<strong>(.*?)</strong>', gggg1)[0]\n",
    "                    gggg1 = re.findall(r'UNII:\\s*([\\w\\d]+)', gggg1)[0]\n",
    "                    gggg1 = \"uniiunii\"+gggg1+\"uniiunii\"+inactive \n",
    "                    newlist.append(gggg1 + 'unii')\n",
    "                \n",
    "            strength = (re.findall('<td class=\"formItem\">([0-9].*?)</td>', tag)) #this finds all strentghs and below removes fluff\n",
    "            for gggg in strength:\n",
    "                if \"BOTTLE\" in gggg:\n",
    "                    continue\n",
    "            \n",
    "                elif \"mm\" in gggg:\n",
    "                    strength.remove(gggg)\n",
    "                    continue\n",
    "                elif \"pieces\" in gggg:\n",
    "                    strength.remove(gggg)\n",
    "                    continue\n",
    "                elif \"/\" in gggg: #this could be a problem for some meds.  dates with slashes showed up in apixiban so added this to remove them\n",
    "                    strength.remove(gggg)\n",
    "                    continue\n",
    "                elif gggg.isdigit(): #this could be a problem.  APixiban had some odd number and this removed it\n",
    "                    strength.remove(gggg)\n",
    "                    continue\n",
    "                newlist.append(gggg + 'stren')\n",
    "        for period in newlist: #this was for the apixiban url.  For some reason it had a period in the newlist\n",
    "            if period == \".\":\n",
    "                newlist.remove(period)\n",
    "                continue\n",
    "        res = [i[0] for i in groupby(newlist)] #this removes duplicate strings next to each other\n",
    "    \n",
    "        hdlist = list() #this list gives the drug name a handle to split on\n",
    "        for drug in res:\n",
    "            if drug == res[2]: #this puts a handle on the third item in the list, which is the main drug\n",
    "                drug = drug + \"111999\"\n",
    "                hdlist.append(drug)\n",
    "            elif drug.endswith('stren'): #this puts a handle on strength\n",
    "                drug = drug + 'stren'\n",
    "                hdlist.append(drug)\n",
    "            elif drug[0].isdigit(): #this puts a handle on the NDC\n",
    "                drug = drug + 'happy'\n",
    "                hdlist.append(drug)\n",
    "            elif drug.endswith('<'): #this puts a handle on the formulation\n",
    "                drug = drug + 'mad'\n",
    "                hdlist.append(drug)\n",
    "            elif drug.endswith('unii'): #this puts a handle on the formulation\n",
    "                drug = drug + 'unii'\n",
    "                hdlist.append(drug)\n",
    "            else:\n",
    "                drug = drug + \"888000\" #this puts a handle on the inactive ingredients\n",
    "                hdlist.append(drug)\n",
    "        try:            \n",
    "            df = pd.DataFrame(hdlist)\n",
    "            df = df.rename(columns = {0 : 'stuff'}) #gives the column a name \"stuff\"\n",
    "            df['MainDrug'] = df['stuff'].apply(lambda x: x.split('111999')[0].strip() if x.count('111999') > 0 else np.nan).fillna(method='ffill') #this pulls all main drug names into a column\n",
    "            df['Inactive'] = df['stuff'].apply(lambda x: x.split('uniiunii')[2].strip() if x.count('uniiunii') > 0 else np.nan).fillna(method=\"ffill\")\n",
    "            df['NDC'] = df['stuff'].apply(lambda x: x.split('happy')[0].strip() if x.count('happy') > 0 else np.nan).fillna(method=\"ffill\")\n",
    "            df['UNII'] = df['stuff'].apply(lambda x: x.split('uniiunii')[1].strip() if x.count('uniiunii') > 0 else np.nan).fillna(method=\"ffill\")\n",
    "            df['Strength'] = df['stuff'].apply(lambda x: x.split('strenstren')[0].strip() if x.count('strenstren') > 0 else np.nan).fillna(method=\"ffill\")\n",
    "            df['Formulation'] = df['stuff'].apply(lambda x: x.split('<mad')[0].strip() if x.count('<mad') > 0 else np.nan).fillna(method=\"ffill\")\n",
    "            df = df.dropna().drop('stuff', axis=1).reindex(columns=['MainDrug', 'NDC','Formulation','Inactive', 'Strength','UNII']).reset_index(drop=True) #for some reason this line removes all inactive except ndcs\n",
    "            df['MainDrug'] = df['MainDrug'].str.lower() #need to make lower case to match that in formulation column\n",
    "            df['Formulation']= df['Formulation'].str.lower()\n",
    "            df['c'] = [Formulation.replace(MainDrug, '') for Formulation, MainDrug in zip(df['Formulation'], df['MainDrug'])] #this drop the main drug in formulation\n",
    "            df = df.drop(['Formulation'], axis=1)\n",
    "            df = df.rename(columns = {'c' : 'Formulation'})\n",
    "            df = df.reindex(columns=['MainDrug', 'NDC', 'Strength', 'Formulation', 'Inactive','UNII']) #this puts the columns in order\n",
    "            df_prev = df['Inactive'].shift(1) #this removes duplicates\n",
    "            df = df[df.Inactive != df_prev] #this removes duplicates\n",
    "            df = df.reset_index().drop_duplicates(subset=['NDC','Inactive'],keep='first').set_index('index') #was getting duplicate inactive, this removes those duplicates\n",
    "            # print(df)\n",
    "            df_total = pd.concat([df_total, df], ignore_index=True)\n",
    "            df_filtered = df_total[~df_total['MainDrug'].str.lower().eq(df_total['Inactive'].str.lower())]\n",
    "            df_filtered.reset_index(drop=True, inplace=True)\n",
    "            # print(df_filtered)\n",
    "            df_filtered.to_csv(iig_file, index=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if os.path.exists(iig_file):\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"{drug} not find on DailyMed\")\n",
    "\n",
    "else:\n",
    "    print(f\"Find {int(x[0])} pages of {drug} on DailyMed\")\n",
    "\n",
    "    totalpages = int(x[0])\n",
    "\n",
    "    # Add 1 because Python range.\n",
    "    url_list = [\"{}&page={}\".format(base_url, str(page)) for page in range(1, totalpages + 1)]\n",
    "    # print(url_list)\n",
    "    df_total = pd.DataFrame()\n",
    "    ## Second Part: Take the lista of links and get a list of those links#######\n",
    "    # fff(url_list)\n",
    "    for fff in url_list:\n",
    "        # For avoid 403-error using User-Agent\n",
    "        req = urllib.request.Request(fff, headers={'User-Agent' : \"Magic Browser\"})\n",
    "        response = urllib.request.urlopen( req )\n",
    "        html = response.read()\n",
    "        # Parsing response\n",
    "        soup = bsoup(html, 'html.parser')\n",
    "        wwwlist= list()\n",
    "        tags= soup('a')\n",
    "        for tag in tags:\n",
    "            mlink = tag.get('href')\n",
    "            wwwlist.append(mlink)\n",
    "        resi = list()\n",
    "        for x in wwwlist:\n",
    "            if x == None:\n",
    "                wwwlist.remove(x)\n",
    "                continue\n",
    "        goodlist = list(filter(None, wwwlist)) #this removes Nonetype from the list, this was a problem\n",
    "        subs = 'dailymed/drugInfo.cfm' #gives  variable to what im looking for\n",
    "        resi = [i for i in goodlist if subs in i] #finds all the links\n",
    "        linklist = list()\n",
    "        for long in resi:\n",
    "            long = \"https://dailymed.nlm.nih.gov\" + long #this add to the full website\n",
    "            linklist.append(long)\n",
    "            continue\n",
    "\n",
    "    ### This takes all the links and adds them to the database####    Note this does not work yet for BRAND and COMBO Drugs\n",
    "\n",
    "        for bbb in linklist:\n",
    "            html = urlopen(bbb).read() #note removed , context=ctx from the urlopen (bbb)\n",
    "            soup = bsoup(html, \"html.parser\")\n",
    "            newlist = list()\n",
    "            tags = soup('td') #this looks through the website and finds tags with \"td\")\n",
    "            for tag in tags:\n",
    "                tag = str(tag)\n",
    "                if tag == \".\":\n",
    "                    tags.remove(tag)\n",
    "                    continue\n",
    "                ndc = (re.findall(\"NDC:(.*?)</td>\", tag)) #finds all the NDCs\n",
    "                for num in ndc:\n",
    "                    num = str(num)\n",
    "                    num = (re.findall(\"([0-9.\\-]+)\", num))\n",
    "                    for small in num:\n",
    "                        shortndc = small[:+10] #trims the NDCS to first 7 digits\n",
    "                        if shortndc not in newlist:\n",
    "                            newlist.append(shortndc)\n",
    "                            continue\n",
    "                ing = (re.findall(\"<strong>(.*?)</strong>\", tag)) #finds all the ingredients\n",
    "                for lala in ing:\n",
    "                \n",
    "                    newlist.append(lala)\n",
    "                    continue\n",
    "                form = (re.findall('<span class=\"contentTableReg\">(.*?)/span>', tag)) #finds all the formulations\n",
    "                for newnew in form:\n",
    "                    newlist.append(newnew)\n",
    "                    continue\n",
    "                strength1 = (re.findall('<td class=\"formItem\">(.*?)</td>', tag)) #this finds all strentghs and below removes fluff\n",
    "                for gggg1 in strength1:\n",
    "                    if '(UNII:' in gggg1:\n",
    "                        # if len(re.findall(r'UNII:\\s*([\\w\\d]+)', gggg1))>0:\n",
    "                        inactive = re.findall(r'<strong>(.*?)</strong>', gggg1)[0]\n",
    "                        gggg1 = re.findall(r'UNII:\\s*([\\w\\d]+)', gggg1)[0]\n",
    "                        gggg1 = \"uniiunii\"+gggg1+\"uniiunii\"+inactive \n",
    "                        newlist.append(gggg1 + 'unii')\n",
    "                    \n",
    "                strength = (re.findall('<td class=\"formItem\">([0-9].*?)</td>', tag)) #this finds all strentghs and below removes fluff\n",
    "                for gggg in strength:\n",
    "                    if \"BOTTLE\" in gggg:\n",
    "                        continue\n",
    "                \n",
    "                    elif \"mm\" in gggg:\n",
    "                        strength.remove(gggg)\n",
    "                        continue\n",
    "                    elif \"pieces\" in gggg:\n",
    "                        strength.remove(gggg)\n",
    "                        continue\n",
    "                    elif \"/\" in gggg: #this could be a problem for some meds.  dates with slashes showed up in apixiban so added this to remove them\n",
    "                        strength.remove(gggg)\n",
    "                        continue\n",
    "                    elif gggg.isdigit(): #this could be a problem.  APixiban had some odd number and this removed it\n",
    "                        strength.remove(gggg)\n",
    "                        continue\n",
    "                    newlist.append(gggg + 'stren')\n",
    "            for period in newlist: #this was for the apixiban url.  For some reason it had a period in the newlist\n",
    "                if period == \".\":\n",
    "                    newlist.remove(period)\n",
    "                    continue\n",
    "            res = [i[0] for i in groupby(newlist)] #this removes duplicate strings next to each other\n",
    "        \n",
    "            hdlist = list() #this list gives the drug name a handle to split on\n",
    "            for drug in res:\n",
    "                if drug == res[2]: #this puts a handle on the third item in the list, which is the main drug\n",
    "                    drug = drug + \"111999\"\n",
    "                    hdlist.append(drug)\n",
    "                elif drug.endswith('stren'): #this puts a handle on strength\n",
    "                    drug = drug + 'stren'\n",
    "                    hdlist.append(drug)\n",
    "                elif drug[0].isdigit(): #this puts a handle on the NDC\n",
    "                    drug = drug + 'happy'\n",
    "                    hdlist.append(drug)\n",
    "                elif drug.endswith('<'): #this puts a handle on the formulation\n",
    "                    drug = drug + 'mad'\n",
    "                    hdlist.append(drug)\n",
    "                elif drug.endswith('unii'): #this puts a handle on the formulation\n",
    "                    drug = drug + 'unii'\n",
    "                    hdlist.append(drug)\n",
    "                else:\n",
    "                    drug = drug + \"888000\" #this puts a handle on the inactive ingredients\n",
    "                    hdlist.append(drug)\n",
    "\n",
    "\n",
    "            df = pd.DataFrame(hdlist)\n",
    "            df = df.rename(columns = {0 : 'stuff'}) #gives the column a name \"stuff\"\n",
    "            df['MainDrug'] = df['stuff'].apply(lambda x: x.split('111999')[0].strip() if x.count('111999') > 0 else np.nan).fillna(method='ffill') #this pulls all main drug names into a column\n",
    "            df['Inactive'] = df['stuff'].apply(lambda x: x.split('uniiunii')[2].strip() if x.count('uniiunii') > 0 else np.nan).fillna(method=\"ffill\")\n",
    "            df['NDC'] = df['stuff'].apply(lambda x: x.split('happy')[0].strip() if x.count('happy') > 0 else np.nan).fillna(method=\"ffill\")\n",
    "            df['UNII'] = df['stuff'].apply(lambda x: x.split('uniiunii')[1].strip() if x.count('uniiunii') > 0 else np.nan).fillna(method=\"ffill\")\n",
    "            df['Strength'] = df['stuff'].apply(lambda x: x.split('strenstren')[0].strip() if x.count('strenstren') > 0 else np.nan).fillna(method=\"ffill\")\n",
    "            df['Formulation'] = df['stuff'].apply(lambda x: x.split('<mad')[0].strip() if x.count('<mad') > 0 else np.nan).fillna(method=\"ffill\")\n",
    "            df = df.dropna().drop('stuff', axis=1).reindex(columns=['MainDrug', 'NDC','Formulation','Inactive', 'Strength','UNII']).reset_index(drop=True) #for some reason this line removes all inactive except ndcs\n",
    "            df['MainDrug'] = df['MainDrug'].str.lower() #need to make lower case to match that in formulation column\n",
    "            df['Formulation']= df['Formulation'].str.lower()\n",
    "            df['c'] = [Formulation.replace(MainDrug, '') for Formulation, MainDrug in zip(df['Formulation'], df['MainDrug'])] #this drop the main drug in formulation\n",
    "            df = df.drop(['Formulation'], axis=1)\n",
    "            df = df.rename(columns = {'c' : 'Formulation'})\n",
    "            df = df.reindex(columns=['MainDrug', 'NDC', 'Strength', 'Formulation', 'Inactive','UNII']) #this puts the columns in order\n",
    "            df_prev = df['Inactive'].shift(1) #this removes duplicates\n",
    "            df = df[df.Inactive != df_prev] #this removes duplicates\n",
    "            df = df.reset_index().drop_duplicates(subset=['NDC','Inactive'],keep='first').set_index('index') #was getting duplicate inactive, this removes those duplicates\n",
    "            # print(df)\n",
    "            df_total = pd.concat([df_total, df], ignore_index=True)\n",
    "            df_filtered = df_total[~df_total['MainDrug'].str.lower().eq(df_total['Inactive'].str.lower())]\n",
    "            df_filtered.reset_index(drop=True, inplace=True)\n",
    "            # print(df_filtered)\n",
    "            df_filtered.to_csv(iig_file, mode='a', index = False, header=True)\n",
    "\n",
    "\n",
    "\n",
    "# create file loading\n",
    "if os.path.exists(iig_file):\n",
    "    with open(iig_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    with open(iig_file, \"w\") as f:\n",
    "        for line in lines:\n",
    "            if line.strip(\"\\n\") != \"MainDrug,NDC,Strength,Formulation,Inactive,UNII\":\n",
    "                f.write(line)\n",
    "    # Add header\n",
    "    with open(iig_file, 'r+') as fp:\n",
    "        lines = fp.readlines()     # lines is list of line, each element '...\\n'\n",
    "        lines.insert(0, 'MainDrug,NDC,Strength,Formulation,Inactive,UNII\\n')  # you can use any index if you know the line index\n",
    "        fp.seek(0)                 # file pointer locates at the beginning to write the whole file again\n",
    "        fp.writelines(lines)       # write whole lists again to the same file\n",
    "    print(f\"Saved file {name_drug} in iigdata\")\n",
    "else:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc598e38-c228-418d-896e-20c2e9b2f3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
